{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1555110810865,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "8JnxRZdFW5Ao",
    "outputId": "2ec0356d-ae8f-4fbe-d3a6-0561771cc6fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/mydrive; to attempt to forcibly remount, call drive.mount(\"/content/mydrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "## If dataset folder is the same directory as the script in Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/mydrive')\n",
    "# path = '/content/mydrive/My Drive/Colab Notebooks/DL/HW6/Hw6_Q1_dataset/HW6_data/'\n",
    "\n",
    "## Local Jupyter Notebook\n",
    "path = '/Hw6_Q1_dataset/HW6_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVm_vt6fxn9V"
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# This is a sketch code for main function. There are some given hyper-parameters insideself.\n",
    "# You need to finish the design and train your network.\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "######################## Hyperparameters #################################\n",
    "# Batch size can be changed if it does not match your memory, please state your batch step_size\n",
    "# in your report.\n",
    "train_batch_size = 10\n",
    "validation_batch_size=10\n",
    "# Please use this learning rate for Q(a) and Q(b)\n",
    "learning_rate = 0.005\n",
    "# This num_epochs is designed for running to be long enough, you need to manually stop or design\n",
    "# your early stopping method.\n",
    "num_epochs = 1000\n",
    "\n",
    "# Design your own dataloader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, input_dir):\n",
    "        self.path = input_dir\n",
    "\n",
    "    def __len__ (self):\n",
    "        folder_name = self.path.split('/')[-1]\n",
    "        if folder_name == 'train':\n",
    "            return 300\n",
    "        else:\n",
    "            return 50\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_temp = str(idx) + \"/\" + str(idx) + \"_input.jpg\"\n",
    "        img_path = os.path.join(self.path, img_temp)\n",
    "        mask_temp = str(idx) + \"/\" + str(idx) + \"_mask.png\"\n",
    "        mask_path = os.path.join(self.path, mask_temp)\n",
    "        \n",
    "        img = plt.imread(img_path)\n",
    "        img = np.atleast_3d(img).transpose(2,0,1).astype(np.float32)\n",
    "        img = torch.from_numpy(img).float()\n",
    "        \n",
    "        mask = plt.imread(mask_path)\n",
    "        mask = (mask * 255).round().astype(np.uint8)\n",
    "        mask = np.atleast_3d(mask).transpose(2,0,1).astype(np.float32)\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        oHot = mask == 0\n",
    "        for i in range(1,8):\n",
    "            oHot = torch.cat([oHot, mask == i*32])\n",
    "            \n",
    "        return img, oHot\n",
    "\n",
    "train_dataset=ImageDataset(input_dir = path+'segmentation/train/')\n",
    "validation_dataset=ImageDataset(input_dir = path+'segmentation/validation/' )\n",
    "test_dataset=ImageDataset(input_dir = path+'segmentation/test/' )\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=train_batch_size,\n",
    "                                           shuffle=True);\n",
    "validation_loader = DataLoader(dataset=validation_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxI3NAsuWzyk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# The network structure is a simplified U-net. You need to finish the last layers\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import numpy as np\n",
    "\n",
    "def add_conv_stage(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, useBN=False):\n",
    "  if useBN:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1)\n",
    "    )\n",
    "  else:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "def add_merge_stage(ch_coarse, ch_fine, in_coarse, in_fine, upsample):\n",
    "  conv = nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  torch.cat(conv, in_fine)\n",
    "\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  )\n",
    "  upsample(in_coarse)\n",
    "\n",
    "def upsample(ch_coarse, ch_fine):\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n",
    "    nn.ReLU()\n",
    "  )\n",
    "\n",
    "class unet(nn.Module):\n",
    "  def __init__(self, useBN=True):\n",
    "    super(unet, self).__init__()\n",
    "    # Downgrade stages\n",
    "    self.conv1   = add_conv_stage(3, 32, useBN=useBN)\n",
    "    self.conv2   = add_conv_stage(32, 64, useBN=useBN)\n",
    "    self.conv3   = add_conv_stage(64, 128, useBN=useBN)\n",
    "    self.conv4   = add_conv_stage(128, 256, useBN=useBN)\n",
    "    # Upgrade stages\n",
    "    self.conv4m = add_conv_stage(512, 256, useBN=useBN)\n",
    "    self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n",
    "    self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n",
    "    self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n",
    "    # Maxpool\n",
    "    self.max_pool = nn.MaxPool2d(2)\n",
    "    # Upsample layers\n",
    "    self.upsample54 = upsample(512, 256)\n",
    "    self.upsample43 = upsample(256, 128)\n",
    "    self.upsample32 = upsample(128,  64)\n",
    "    self.upsample21 = upsample(64 ,  32)\n",
    "    ## weight initialization\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          m.bias.data.zero_()\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    self.conv_last = nn.Conv2d(32, 8, 1)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    conv1_out = self.conv1(x)\n",
    "    conv2_out = self.conv2(self.max_pool(conv1_out))\n",
    "    conv3_out = self.conv3(self.max_pool(conv2_out))\n",
    "    conv4_out = self.conv4(self.max_pool(conv3_out))\n",
    "\n",
    "    conv4m_out_ = torch.cat((self.upsample43(conv4_out), conv3_out), 1)\n",
    "    conv3m_out = self.conv3m(conv4m_out_)\n",
    "\n",
    "    conv3m_out_ = torch.cat((self.upsample32(conv3m_out), conv2_out), 1)\n",
    "    conv2m_out = self.conv2m(conv3m_out_)\n",
    "\n",
    "    conv2m_out_ = torch.cat((self.upsample21(conv2m_out), conv1_out), 1)\n",
    "    conv1m_out = self.conv1m(conv2m_out_)\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    out = self.conv_last(conv1m_out)\n",
    "    out = torch.sigmoid(out)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OrYRo_Ew0d2"
   },
   "outputs": [],
   "source": [
    "def dice_loss(output, labels):\n",
    "  output = output.contiguous()\n",
    "  labels = labels.contiguous()\n",
    "  \n",
    "  tp = (output*labels).sum(dim=2).sum(dim=2)\n",
    "  tpfp = output.sum(dim=2).sum(dim=2)\n",
    "  tpfn = labels.sum(dim=2).sum(dim=2)\n",
    "  loss = (1 - ( (2.*tp + 1e-7) / (tpfp+tpfn+1e-7) ) )\n",
    "  \n",
    "  return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1846
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2683931,
     "status": "error",
     "timestamp": 1555113500950,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "ohneYiithP69",
    "outputId": "fc4ea6cf-b40f-44fd-a8e4-dd8eb3549239"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started!\n",
      "\n",
      "EPOCH 1 of 1000\n",
      "\n",
      "Training Loss: 0.8701\n",
      "3m 5s\n",
      "Validation Loss: 0.9036\n",
      "0m 58s\n",
      "\n",
      "EPOCH 2 of 1000\n",
      "\n",
      "Training Loss: 0.8468\n",
      "2m 57s\n",
      "Validation Loss: 0.8295\n",
      "0m 60s\n",
      "\n",
      "EPOCH 3 of 1000\n",
      "\n",
      "Training Loss: 0.8127\n",
      "2m 54s\n",
      "Validation Loss: 0.8644\n",
      "0m 56s\n",
      "\n",
      "EPOCH 4 of 1000\n",
      "\n",
      "Training Loss: 0.6811\n",
      "22m 42s\n",
      "Validation Loss: 0.6695\n",
      "0m 39s\n",
      "\n",
      "EPOCH 5 of 1000\n",
      "\n",
      "Training Loss: 0.5961\n",
      "2m 20s\n",
      "Validation Loss: 0.6695\n",
      "0m 37s\n",
      "\n",
      "EPOCH 6 of 1000\n",
      "\n",
      "Training Loss: 0.5961\n",
      "2m 3s\n",
      "Validation Loss: 0.6695\n",
      "0m 38s\n",
      "\n",
      "EPOCH 7 of 1000\n",
      "\n",
      "Training Loss: 0.5961\n",
      "2m 2s\n",
      "Validation Loss: 0.6695\n",
      "0m 38s\n",
      "\n",
      "EPOCH 8 of 1000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c8a3e5310fe8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Forward + Backward + Optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-6b8021cf9214>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mconv1_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mconv2_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv1_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0mconv3_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv2_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mconv4_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv3_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 320\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = unet();\n",
    "\n",
    "import time\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(\"Training Started!\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "converge_epoch = []\n",
    "for epoch in range(num_epochs):\n",
    "    ########################### Training #####################################\n",
    "    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
    "    # Please design your own training section\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "        \n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "\n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Training Loss: %.4f\" % (mean_loss))\n",
    "    train_losses.append(mean_loss)\n",
    "    converge_epoch.append(epoch)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    ########################### Validation #####################################\n",
    "    # Please design your own validation section\n",
    "    model.eval()\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "\n",
    "    for (images, labels) in validation_loader:\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        losses.append(loss.data.item())\n",
    "    \n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Validation Loss: %.4f\" % (mean_loss))\n",
    "    val_losses.append(mean_loss)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    ### Early Stopping\n",
    "    if epoch > 13 and abs(mean_loss - val_losses[epoch-1]) <= 0.001:\n",
    "        print('The validation loss converges')\n",
    "        break\n",
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1555113511673,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "gfRS-jMeO7rK",
    "outputId": "cfb8d12a-3080-4db2-99ed-eb437c4fa81a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 38698,
     "status": "ok",
     "timestamp": 1555113557153,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "qzu4jTvUWzyz",
    "outputId": "f946f54c-3fa7-4df5-f0d4-edf647dca075"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance - DICE score: 0.3342\n",
      "0m 38s\n"
     ]
    }
   ],
   "source": [
    "########################### Testing #####################################\n",
    "# Please design your own validation section\n",
    "model.eval()\n",
    "since = time.time()\n",
    "losses=[]\n",
    "\n",
    "for (images, labels) in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    labels = Variable(labels.float())\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss = dice_loss(outputs, labels)\n",
    "    losses.append(loss.data.item())\n",
    "\n",
    "### Average Batch Loss\n",
    "mean_loss = sum(losses)/len(losses)\n",
    "print(\"Testing performance - DICE score: %.4f\" % (1-mean_loss))\n",
    "\n",
    "### Timing\n",
    "time_elapsed = time.time() - since\n",
    "print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yi9Wa1YZ_SUq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Xi_Wang_HW6_Q1c**.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
