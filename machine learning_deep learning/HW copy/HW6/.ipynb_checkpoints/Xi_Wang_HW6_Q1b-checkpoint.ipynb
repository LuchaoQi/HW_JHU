{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1555103283888,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "8JnxRZdFW5Ao",
    "outputId": "f51b4046-9e9a-4c3c-c6c2-1a1a53bbbbe0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/mydrive; to attempt to forcibly remount, call drive.mount(\"/content/mydrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "## If dataset folder is the same directory as the script in Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/mydrive')\n",
    "# path = '/content/mydrive/My Drive/Colab Notebooks/DL/HW6/Hw6_Q1_dataset/HW6_data/'\n",
    "\n",
    "## Local Jupyter Notebook\n",
    "path = '/Hw6_Q1_dataset/HW6_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVm_vt6fxn9V"
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# This is a sketch code for main function. There are some given hyper-parameters insideself.\n",
    "# You need to finish the design and train your network.\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "######################## Hyperparameters #################################\n",
    "# Batch size can be changed if it does not match your memory, please state your batch step_size\n",
    "# in your report.\n",
    "train_batch_size = 10\n",
    "validation_batch_size=10\n",
    "# Please use this learning rate for Q(a) and Q(b)\n",
    "learning_rate = 0.001\n",
    "# This num_epochs is designed for running to be long enough, you need to manually stop or design\n",
    "# your early stopping method.\n",
    "num_epochs = 1000\n",
    "\n",
    "# Design your own dataloader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, input_dir):\n",
    "        self.path = input_dir\n",
    "\n",
    "    def __len__ (self):\n",
    "        folder_name = self.path.split('/')[-1]\n",
    "        if folder_name == 'train':\n",
    "            return 300\n",
    "        else:\n",
    "            return 50\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_temp = str(idx) + \"/\" + str(idx) + \"_input.jpg\"\n",
    "        img_path = os.path.join(self.path, img_temp)\n",
    "        mask_temp = str(idx) + \"/\" + str(idx) + \"_mask.png\"\n",
    "        mask_path = os.path.join(self.path, mask_temp)\n",
    "        \n",
    "        img = plt.imread(img_path)\n",
    "        img = np.atleast_3d(img).transpose(2,0,1).astype(np.float32)\n",
    "        img = torch.from_numpy(img).float()\n",
    "        \n",
    "        mask = plt.imread(mask_path)\n",
    "        mask = (mask * 255).round().astype(np.uint8)\n",
    "        mask = np.atleast_3d(mask).transpose(2,0,1).astype(np.float32)\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        oHot = mask == 0\n",
    "        for i in range(1,8):\n",
    "            oHot = torch.cat([oHot, mask == i*32])\n",
    "            \n",
    "        return img, oHot\n",
    "\n",
    "train_dataset=ImageDataset(input_dir = path+'segmentation/train/')\n",
    "validation_dataset=ImageDataset(input_dir = path+'segmentation/validation/' )\n",
    "test_dataset=ImageDataset(input_dir = path+'segmentation/test/' )\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=train_batch_size,\n",
    "                                           shuffle=True);\n",
    "validation_loader = DataLoader(dataset=validation_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxI3NAsuWzyk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# The network structure is a simplified U-net. You need to finish the last layers\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import numpy as np\n",
    "\n",
    "def add_conv_stage(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, useBN=False):\n",
    "  if useBN:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1)\n",
    "    )\n",
    "  else:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "def add_merge_stage(ch_coarse, ch_fine, in_coarse, in_fine, upsample):\n",
    "  conv = nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  torch.cat(conv, in_fine)\n",
    "\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  )\n",
    "  upsample(in_coarse)\n",
    "\n",
    "def upsample(ch_coarse, ch_fine):\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n",
    "    nn.ReLU()\n",
    "  )\n",
    "\n",
    "class unet(nn.Module):\n",
    "  def __init__(self, useBN=False):\n",
    "    super(unet, self).__init__()\n",
    "    # Downgrade stages\n",
    "    self.conv1   = add_conv_stage(3, 32, useBN=useBN)\n",
    "    self.conv2   = add_conv_stage(32, 64, useBN=useBN)\n",
    "    self.conv3   = add_conv_stage(64, 128, useBN=useBN)\n",
    "    self.conv4   = add_conv_stage(128, 256, useBN=useBN)\n",
    "    # Upgrade stages\n",
    "    self.conv4m = add_conv_stage(512, 256, useBN=useBN)\n",
    "    self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n",
    "    self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n",
    "    self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n",
    "    # Maxpool\n",
    "    self.max_pool = nn.MaxPool2d(2)\n",
    "    # Upsample layers\n",
    "    self.upsample54 = upsample(512, 256)\n",
    "    self.upsample43 = upsample(256, 128)\n",
    "    self.upsample32 = upsample(128,  64)\n",
    "    self.upsample21 = upsample(64 ,  32)\n",
    "    ## weight initialization\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        if m.bias is not None:\n",
    "          m.bias.data.zero_()\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    self.conv_last = nn.Conv2d(32, 8, 1)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    conv1_out = self.conv1(x)\n",
    "    conv2_out = self.conv2(self.max_pool(conv1_out))\n",
    "    conv3_out = self.conv3(self.max_pool(conv2_out))\n",
    "    conv4_out = self.conv4(self.max_pool(conv3_out))\n",
    "\n",
    "    conv4m_out_ = torch.cat((self.upsample43(conv4_out), conv3_out), 1)\n",
    "    conv3m_out = self.conv3m(conv4m_out_)\n",
    "\n",
    "    conv3m_out_ = torch.cat((self.upsample32(conv3m_out), conv2_out), 1)\n",
    "    conv2m_out = self.conv2m(conv3m_out_)\n",
    "\n",
    "    conv2m_out_ = torch.cat((self.upsample21(conv2m_out), conv1_out), 1)\n",
    "    conv1m_out = self.conv1m(conv2m_out_)\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    out = self.conv_last(conv1m_out)\n",
    "    out = torch.sigmoid(out)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OrYRo_Ew0d2"
   },
   "outputs": [],
   "source": [
    "def dice_loss(output, labels):\n",
    "  output = output.contiguous()\n",
    "  labels = labels.contiguous()\n",
    "  \n",
    "  tp = (output*labels).sum(dim=2).sum(dim=2)\n",
    "  tpfp = output.sum(dim=2).sum(dim=2)\n",
    "  tpfn = labels.sum(dim=2).sum(dim=2)\n",
    "  loss = (1 - ( (2.*tp + 1e-7) / (tpfp+tpfn+1e-7) ) )\n",
    "  \n",
    "  return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3139
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2136448,
     "status": "error",
     "timestamp": 1555105421689,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "ohneYiithP69",
    "outputId": "8ccc069a-a958-4c04-e6fa-dd17670aca67",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started!\n",
      "\n",
      "EPOCH 1 of 1000\n",
      "\n",
      "Training Loss: 0.8551\n",
      "1m 22s\n",
      "Validation Loss: 0.8577\n",
      "0m 33s\n",
      "\n",
      "EPOCH 2 of 1000\n",
      "\n",
      "Training Loss: 0.8465\n",
      "0m 57s\n",
      "Validation Loss: 0.8588\n",
      "0m 32s\n",
      "\n",
      "EPOCH 3 of 1000\n",
      "\n",
      "Training Loss: 0.8357\n",
      "0m 58s\n",
      "Validation Loss: 0.8591\n",
      "0m 32s\n",
      "\n",
      "EPOCH 4 of 1000\n",
      "\n",
      "Training Loss: 0.8361\n",
      "0m 59s\n",
      "Validation Loss: 0.8596\n",
      "0m 38s\n",
      "\n",
      "EPOCH 5 of 1000\n",
      "\n",
      "Training Loss: 0.8313\n",
      "1m 17s\n",
      "Validation Loss: 0.8594\n",
      "0m 32s\n",
      "\n",
      "EPOCH 6 of 1000\n",
      "\n",
      "Training Loss: 0.8304\n",
      "0m 58s\n",
      "Validation Loss: 0.8574\n",
      "0m 32s\n",
      "\n",
      "EPOCH 7 of 1000\n",
      "\n",
      "Training Loss: 0.8276\n",
      "0m 58s\n",
      "Validation Loss: 0.8562\n",
      "0m 32s\n",
      "\n",
      "EPOCH 8 of 1000\n",
      "\n",
      "Training Loss: 0.8274\n",
      "0m 58s\n",
      "Validation Loss: 0.8569\n",
      "0m 32s\n",
      "\n",
      "EPOCH 9 of 1000\n",
      "\n",
      "Training Loss: 0.8173\n",
      "0m 57s\n",
      "Validation Loss: 0.8506\n",
      "0m 32s\n",
      "\n",
      "EPOCH 10 of 1000\n",
      "\n",
      "Training Loss: 0.8010\n",
      "0m 57s\n",
      "Validation Loss: 0.8374\n",
      "0m 32s\n",
      "\n",
      "EPOCH 11 of 1000\n",
      "\n",
      "Training Loss: 0.7878\n",
      "0m 57s\n",
      "Validation Loss: 0.8380\n",
      "0m 32s\n",
      "\n",
      "EPOCH 12 of 1000\n",
      "\n",
      "Training Loss: 0.7650\n",
      "0m 57s\n",
      "Validation Loss: 0.8358\n",
      "0m 32s\n",
      "\n",
      "EPOCH 13 of 1000\n",
      "\n",
      "Training Loss: 0.7649\n",
      "0m 57s\n",
      "Validation Loss: 0.8339\n",
      "0m 32s\n",
      "\n",
      "EPOCH 14 of 1000\n",
      "\n",
      "Training Loss: 0.7587\n",
      "0m 57s\n",
      "Validation Loss: 0.8340\n",
      "0m 32s\n",
      "\n",
      "EPOCH 15 of 1000\n",
      "\n",
      "Training Loss: 0.7593\n",
      "0m 57s\n",
      "Validation Loss: 0.8296\n",
      "0m 32s\n",
      "\n",
      "EPOCH 16 of 1000\n",
      "\n",
      "Training Loss: 0.7346\n",
      "0m 58s\n",
      "Validation Loss: 0.8271\n",
      "0m 32s\n",
      "\n",
      "EPOCH 17 of 1000\n",
      "\n",
      "Training Loss: 0.7134\n",
      "0m 57s\n",
      "Validation Loss: 0.8311\n",
      "0m 32s\n",
      "\n",
      "EPOCH 18 of 1000\n",
      "\n",
      "Training Loss: 0.7271\n",
      "0m 58s\n",
      "Validation Loss: 0.8238\n",
      "0m 32s\n",
      "\n",
      "EPOCH 19 of 1000\n",
      "\n",
      "Training Loss: 0.7333\n",
      "0m 59s\n",
      "Validation Loss: 0.8198\n",
      "0m 33s\n",
      "\n",
      "EPOCH 20 of 1000\n",
      "\n",
      "Training Loss: 0.7143\n",
      "0m 59s\n",
      "Validation Loss: 0.8240\n",
      "0m 31s\n",
      "\n",
      "EPOCH 21 of 1000\n",
      "\n",
      "Training Loss: 0.7040\n",
      "1m 11s\n",
      "Validation Loss: 0.8254\n",
      "0m 55s\n",
      "\n",
      "EPOCH 22 of 1000\n",
      "\n",
      "Training Loss: 0.7329\n",
      "1m 41s\n",
      "Validation Loss: 0.8234\n",
      "0m 45s\n",
      "\n",
      "EPOCH 23 of 1000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-5fdee9bba876>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = unet();\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(\"Training Started!\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "converge_epoch = []\n",
    "for epoch in range(num_epochs):\n",
    "    ########################### Training #####################################\n",
    "    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
    "    # Please design your own training section\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "\n",
    "        ### Data Augmentation\n",
    "        i_ver = copy.deepcopy(images)  ## image vertical flip\n",
    "        i_hor = copy.deepcopy(images)  ## image horizontal flip\n",
    "        v_ver = copy.deepcopy(labels)  ## labels vertical flip\n",
    "        v_hor = copy.deepcopy(labels)  ## labels horizontal flip\n",
    "\n",
    "        for i in range(train_batch_size):\n",
    "            for p in range(3):\n",
    "                i_ver[i][p] = torch.from_numpy(np.flipud(images[i][p]).copy())\n",
    "                i_hor[i][p] = torch.from_numpy(np.fliplr(images[i][p]).copy())\n",
    "            for q in range(8):\n",
    "                v_ver[i][q] = torch.from_numpy(np.flipud(labels[i][q]).copy())\n",
    "                v_hor[i][q] = torch.from_numpy(np.fliplr(labels[i][q]).copy())\n",
    "        \n",
    "        # Regular Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "        # Vertical Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(i_ver)\n",
    "        loss = dice_loss(outputs, v_ver)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "        # Horizontal Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(i_hor)\n",
    "        loss = dice_loss(outputs, v_hor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "\n",
    "        break\n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Training Loss: %.4f\" % (mean_loss))\n",
    "    train_losses.append(mean_loss)\n",
    "    converge_epoch.append(epoch)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    ########################### Validation #####################################\n",
    "    # Please design your own validation section\n",
    "    model.eval()\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "\n",
    "    for (images, labels) in validation_loader:\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        losses.append(loss.data.item())\n",
    "    \n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Validation Loss: %.4f\" % (mean_loss))\n",
    "    val_losses.append(mean_loss)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    ### Early Stopping\n",
    "    if epoch > 13 and abs(mean_loss - val_losses[epoch-1]) <= 0.001:\n",
    "        print('The validation loss converges')\n",
    "        break\n",
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1042,
     "status": "ok",
     "timestamp": 1555105428471,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "gfRS-jMeO7rK",
    "outputId": "ec16bbbc-3097-4aea-b900-57b6d973ec6d"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/Qz+/utVs02wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 45458,
     "status": "ok",
     "timestamp": 1555105486695,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "yusfwz_ib5DF",
    "outputId": "c7aaccc6-9c2d-4d80-8489-e41dd6e758fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance - DICE score: 0.1926\n",
      "0m 45s\n"
     ]
    }
   ],
   "source": [
    "########################### Testing #####################################\n",
    "# Please design your own validation section\n",
    "model.eval()\n",
    "since = time.time()\n",
    "losses=[]\n",
    "\n",
    "for (images, labels) in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    labels = Variable(labels.float())\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss = dice_loss(outputs, labels)\n",
    "    losses.append(loss.data.item())\n",
    "\n",
    "### Average Batch Loss\n",
    "mean_loss = sum(losses)/len(losses)\n",
    "print(\"Testing performance - DICE score: %.4f\" % (1-mean_loss))\n",
    "\n",
    "### Timing\n",
    "time_elapsed = time.time() - since\n",
    "print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N3z01EjBgeWe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Xi_Wang_HW6_Q1b.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
