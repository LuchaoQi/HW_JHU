{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 699,
     "status": "ok",
     "timestamp": 1555203825070,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "8JnxRZdFW5Ao",
    "outputId": "9aded548-f902-4da9-b5b5-4527c199f8de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/mydrive; to attempt to forcibly remount, call drive.mount(\"/content/mydrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "## If dataset folder is the same directory as the script in Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/mydrive')\n",
    "# path = '/content/mydrive/My Drive/Colab Notebooks/DL/HW6/Hw6_Q1_dataset/HW6_data/'\n",
    "\n",
    "## Local Jupyter Notebook\n",
    "path = '/Hw6_Q1_dataset/HW6_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVm_vt6fxn9V"
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# This is a sketch code for main function. There are some given hyper-parameters insideself.\n",
    "# You need to finish the design and train your network.\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "######################## Hyperparameters #################################\n",
    "# Batch size can be changed if it does not match your memory, please state your batch step_size\n",
    "# in your report.\n",
    "train_batch_size = 25\n",
    "validation_batch_size=10\n",
    "# Please use this learning rate for Q(a) and Q(b)\n",
    "learning_rate = 0.005 ## Originally 0.001\n",
    "# This num_epochs is designed for running to be long enough, you need to manually stop or design\n",
    "# your early stopping method.\n",
    "num_epochs = 1000\n",
    "\n",
    "# Design your own dataloader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, input_dir):\n",
    "        self.path = input_dir\n",
    "\n",
    "    def __len__ (self):\n",
    "        folder_name = self.path.split('/')[-2]\n",
    "        if folder_name == 'train':\n",
    "            return 300\n",
    "        else:\n",
    "            return 50\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_temp = str(idx) + \"/\" + str(idx) + \"_input.jpg\"\n",
    "        img_path = os.path.join(self.path, img_temp)\n",
    "        mask_temp = str(idx) + \"/\" + str(idx) + \"_mask.png\"\n",
    "        mask_path = os.path.join(self.path, mask_temp)\n",
    "        \n",
    "        img = plt.imread(img_path)\n",
    "        img = np.atleast_3d(img).transpose(2,0,1).astype(np.float32)\n",
    "        img = torch.from_numpy(img).float()\n",
    "        \n",
    "        mask = plt.imread(mask_path)\n",
    "        mask = (mask * 255).round().astype(np.uint8)\n",
    "        mask = np.atleast_3d(mask).transpose(2,0,1).astype(np.float32)\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        oHot = mask == 0\n",
    "        for i in range(1,8):\n",
    "            oHot = torch.cat([oHot, mask == i*32])\n",
    "            \n",
    "        return img, oHot\n",
    "\n",
    "train_dataset=ImageDataset(input_dir = path+'segmentation/train/')\n",
    "validation_dataset=ImageDataset(input_dir = path+'segmentation/validation/' )\n",
    "test_dataset=ImageDataset(input_dir = path+'segmentation/test/' )\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=train_batch_size,\n",
    "                                           shuffle=True);\n",
    "validation_loader = DataLoader(dataset=validation_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxI3NAsuWzyk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# The network structure is a simplified U-net. You need to finish the last layers\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import numpy as np\n",
    "\n",
    "def add_conv_stage(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, useBN=True):\n",
    "  if useBN:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1)\n",
    "    )\n",
    "  else:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "def add_merge_stage(ch_coarse, ch_fine, in_coarse, in_fine, upsample):\n",
    "  conv = nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  torch.cat(conv, in_fine)\n",
    "\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  )\n",
    "  upsample(in_coarse)\n",
    "\n",
    "def upsample(ch_coarse, ch_fine):\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n",
    "    nn.ReLU()\n",
    "  )\n",
    "\n",
    "class unet(nn.Module):\n",
    "  def __init__(self, useBN=True):\n",
    "    super(unet, self).__init__()\n",
    "    # Downgrade stages\n",
    "    self.conv1   = add_conv_stage(1, 32, useBN=useBN)\n",
    "    self.conv1E   = add_conv_stage(3, 32, useBN=useBN)\n",
    "    self.conv2   = add_conv_stage(32, 64, useBN=useBN)\n",
    "    self.conv3   = add_conv_stage(64, 128, useBN=useBN)\n",
    "    self.conv4   = add_conv_stage(128, 256, useBN=useBN)\n",
    "    # Upgrade stages\n",
    "    self.conv4m = add_conv_stage(512, 256, useBN=useBN)\n",
    "    self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n",
    "    self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n",
    "    self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n",
    "    # Maxpool\n",
    "    self.max_pool = nn.MaxPool2d(2)\n",
    "    # Upsample layers\n",
    "    self.upsample54 = upsample(512, 256)\n",
    "    self.upsample43 = upsample(256, 128)\n",
    "    self.upsample32 = upsample(128,  64)\n",
    "    self.upsample21 = upsample(64 ,  32)\n",
    "    ## weight initialization\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "          m.bias.data.zero_()\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    self.conv_last = nn.Conv2d(32, 3, 1)\n",
    "    self.conv_lastE = nn.Conv2d(32, 8, 1)\n",
    "    self.activation = nn.LeakyReLU(0.1)\n",
    "    self.activationE = nn.Sigmoid()\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    conv1_out = self.conv1E(x)\n",
    "    conv2_out = self.conv2(self.max_pool(conv1_out))\n",
    "    conv3_out = self.conv3(self.max_pool(conv2_out))\n",
    "    conv4_out = self.conv4(self.max_pool(conv3_out))\n",
    "\n",
    "    conv4m_out_ = torch.cat((self.upsample43(conv4_out), conv3_out), 1)\n",
    "    conv3m_out = self.conv3m(conv4m_out_)\n",
    "\n",
    "    conv3m_out_ = torch.cat((self.upsample32(conv3m_out), conv2_out), 1)\n",
    "    conv2m_out = self.conv2m(conv3m_out_)\n",
    "\n",
    "    conv2m_out_ = torch.cat((self.upsample21(conv2m_out), conv1_out), 1)\n",
    "    conv1m_out = self.conv1m(conv2m_out_)\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    out = self.conv_lastE(conv1m_out)\n",
    "    out = self.activationE(out)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHrqfZgDWvA6"
   },
   "outputs": [],
   "source": [
    "model = unet();\n",
    "model.load_state_dict(torch.load(path+'yourmodel.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OrYRo_Ew0d2"
   },
   "outputs": [],
   "source": [
    "def dice_loss(output, labels):\n",
    "  output = output.contiguous()\n",
    "  labels = labels.contiguous()\n",
    "  \n",
    "  tp = (output*labels).sum(dim=2).sum(dim=2)\n",
    "  tpfp = output.sum(dim=2).sum(dim=2)\n",
    "  tpfn = labels.sum(dim=2).sum(dim=2)\n",
    "  loss = (1 - ( (2.*tp + 1e-7) / (tpfp+tpfn+1e-7) ) )\n",
    "  \n",
    "  return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2061
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 455678,
     "status": "error",
     "timestamp": 1555204280115,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "ohneYiithP69",
    "outputId": "35bffa68-0a2e-4c20-d4ca-80e5ecbb114a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started!\n",
      "\n",
      "EPOCH 1 of 1000\n",
      "\n",
      ". Training Loss: 0.8333\n",
      "0m 28s\n",
      "Validation Loss: 0.8454\n",
      "0m 3s\n",
      "\n",
      "EPOCH 2 of 1000\n",
      "\n",
      ". Training Loss: 0.7779\n",
      "0m 27s\n",
      "Validation Loss: 0.7523\n",
      "0m 3s\n",
      "\n",
      "EPOCH 3 of 1000\n",
      "\n",
      ". Training Loss: 0.7555\n",
      "0m 27s\n",
      "Validation Loss: 0.7562\n",
      "0m 3s\n",
      "\n",
      "EPOCH 4 of 1000\n",
      "\n",
      ". Training Loss: 0.7531\n",
      "0m 27s\n",
      "Validation Loss: 0.7451\n",
      "0m 3s\n",
      "\n",
      "EPOCH 5 of 1000\n",
      "\n",
      ". Training Loss: 0.7448\n",
      "0m 27s\n",
      "Validation Loss: 0.7425\n",
      "0m 3s\n",
      "\n",
      "EPOCH 6 of 1000\n",
      "\n",
      ". Training Loss: 0.7526\n",
      "0m 27s\n",
      "Validation Loss: 0.7499\n",
      "0m 3s\n",
      "\n",
      "EPOCH 7 of 1000\n",
      "\n",
      ". Training Loss: 0.7465\n",
      "0m 27s\n",
      "Validation Loss: 0.7425\n",
      "0m 3s\n",
      "\n",
      "EPOCH 8 of 1000\n",
      "\n",
      ". Training Loss: 0.7331\n",
      "0m 27s\n",
      "Validation Loss: 0.7420\n",
      "0m 3s\n",
      "\n",
      "EPOCH 9 of 1000\n",
      "\n",
      ". Training Loss: 0.7569\n",
      "0m 27s\n",
      "Validation Loss: 0.7497\n",
      "0m 3s\n",
      "\n",
      "EPOCH 10 of 1000\n",
      "\n",
      ". Training Loss: 0.6228\n",
      "0m 26s\n",
      "Validation Loss: 0.2184\n",
      "0m 3s\n",
      "\n",
      "EPOCH 11 of 1000\n",
      "\n",
      ". Training Loss: 0.2294\n",
      "0m 26s\n",
      "Validation Loss: 0.2184\n",
      "0m 3s\n",
      "\n",
      "EPOCH 12 of 1000\n",
      "\n",
      ". Training Loss: 0.2294\n",
      "0m 26s\n",
      "Validation Loss: 0.2184\n",
      "0m 3s\n",
      "\n",
      "EPOCH 13 of 1000\n",
      "\n",
      ". Training Loss: 0.2294\n",
      "0m 26s\n",
      "Validation Loss: 0.2184\n",
      "0m 3s\n",
      "\n",
      "EPOCH 14 of 1000\n",
      "\n",
      ". Training Loss: 0.2294\n",
      "0m 26s\n",
      "Validation Loss: 0.2184\n",
      "0m 3s\n",
      "\n",
      "EPOCH 15 of 1000\n",
      "\n",
      ". Training Loss: 0.2294\n",
      "0m 26s\n",
      "Validation Loss: 0.2184\n",
      "0m 3s\n",
      "\n",
      "EPOCH 16 of 1000\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cfaa75b3d0fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available(): #use gpu if available\n",
    "    model.cuda()\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(\"Training Started!\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "converge_epoch = []\n",
    "for epoch in range(num_epochs):\n",
    "    ########################### Training #####################################\n",
    "    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
    "    # Please design your own training section\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "    bar = 0\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "        \n",
    "        # Regular Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images.cuda())\n",
    "        loss = dice_loss(outputs, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "        bar += 1\n",
    "        if bar == 10:\n",
    "            print('.', end=\" \")\n",
    "            bar = 0\n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Training Loss: %.4f\" % (mean_loss))\n",
    "    train_losses.append(mean_loss)\n",
    "    converge_epoch.append(epoch)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    ########################### Validation #####################################\n",
    "    # Please design your own validation section\n",
    "    model.eval()\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "\n",
    "    for (images, labels) in validation_loader:\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "\n",
    "        outputs = model(images.cuda())\n",
    "        loss = dice_loss(outputs, labels.cuda())\n",
    "        losses.append(loss.data.item())\n",
    "    \n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Validation Loss: %.4f\" % (mean_loss))\n",
    "    val_losses.append(mean_loss)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    ### Early Stopping\n",
    "    if epoch > 13 and abs(mean_loss - val_losses[epoch-1]) <= 1e-6:\n",
    "        print('The validation loss converges')\n",
    "        break\n",
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 720,
     "status": "ok",
     "timestamp": 1555204284592,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "gfRS-jMeO7rK",
    "outputId": "758d3ee7-6e3d-4ef9-b135-c49540d099d3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 27296,
     "status": "ok",
     "timestamp": 1555204316582,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "yusfwz_ib5DF",
    "outputId": "a1d66c11-75db-4cfe-bce2-f132d2f1960b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance - DICE score: 0.7622\n",
      "0m 27s\n"
     ]
    }
   ],
   "source": [
    "########################### Testing #####################################\n",
    "# Please design your own validation section\n",
    "model.eval()\n",
    "since = time.time()\n",
    "losses=[]\n",
    "\n",
    "for (images, labels) in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    labels = Variable(labels.float())\n",
    "\n",
    "    outputs = model(images.cuda())\n",
    "    loss = dice_loss(outputs, labels.cuda())\n",
    "    losses.append(loss.data.item())\n",
    "\n",
    "### Average Batch Loss\n",
    "mean_loss = sum(losses)/len(losses)\n",
    "print(\"Testing performance - DICE score: %.4f\" % (1-mean_loss))\n",
    "\n",
    "### Timing\n",
    "time_elapsed = time.time() - since\n",
    "print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgqA56p3vBoT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Xi_Wang_HW6_Q1e.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
