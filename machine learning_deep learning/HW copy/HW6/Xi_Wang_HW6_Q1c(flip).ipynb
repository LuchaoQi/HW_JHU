{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2102,
     "status": "ok",
     "timestamp": 1555107091680,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "8JnxRZdFW5Ao",
    "outputId": "e88bacb5-4397-4ba4-b8c9-b15306d62011"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/mydrive; to attempt to forcibly remount, call drive.mount(\"/content/mydrive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "## If dataset folder is the same directory as the script in Google Colab\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/mydrive')\n",
    "# path = '/content/mydrive/My Drive/Colab Notebooks/DL/HW6/Hw6_Q1_dataset/HW6_data/'\n",
    "\n",
    "## Local Jupyter Notebook\n",
    "path = '/Hw6_Q1_dataset/HW6_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eVm_vt6fxn9V"
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# This is a sketch code for main function. There are some given hyper-parameters insideself.\n",
    "# You need to finish the design and train your network.\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "######################## Hyperparameters #################################\n",
    "# Batch size can be changed if it does not match your memory, please state your batch step_size\n",
    "# in your report.\n",
    "train_batch_size = 10\n",
    "validation_batch_size=10\n",
    "# Please use this learning rate for Q(a) and Q(b)\n",
    "learning_rate = 0.01 ## Originally 0.001\n",
    "# This num_epochs is designed for running to be long enough, you need to manually stop or design\n",
    "# your early stopping method.\n",
    "num_epochs = 1000\n",
    "\n",
    "# Design your own dataloader\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, input_dir):\n",
    "        self.path = input_dir\n",
    "\n",
    "    def __len__ (self):\n",
    "        folder_name = self.path.split('/')[-1]\n",
    "        if folder_name == 'train':\n",
    "            return 300\n",
    "        else:\n",
    "            return 50\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        img_temp = str(idx) + \"/\" + str(idx) + \"_input.jpg\"\n",
    "        img_path = os.path.join(self.path, img_temp)\n",
    "        mask_temp = str(idx) + \"/\" + str(idx) + \"_mask.png\"\n",
    "        mask_path = os.path.join(self.path, mask_temp)\n",
    "        \n",
    "        img = plt.imread(img_path)\n",
    "        img = np.atleast_3d(img).transpose(2,0,1).astype(np.float32)\n",
    "        img = torch.from_numpy(img).float()\n",
    "        \n",
    "        mask = plt.imread(mask_path)\n",
    "        mask = (mask * 255).round().astype(np.uint8)\n",
    "        mask = np.atleast_3d(mask).transpose(2,0,1).astype(np.float32)\n",
    "        mask = torch.from_numpy(mask).float()\n",
    "        oHot = mask == 0\n",
    "        for i in range(1,8):\n",
    "            oHot = torch.cat([oHot, mask == i*32])\n",
    "            \n",
    "        return img, oHot\n",
    "\n",
    "train_dataset=ImageDataset(input_dir = path+'segmentation/train/')\n",
    "validation_dataset=ImageDataset(input_dir = path+'segmentation/validation/' )\n",
    "test_dataset=ImageDataset(input_dir = path+'segmentation/test/' )\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=train_batch_size,\n",
    "                                           shuffle=True);\n",
    "validation_loader = DataLoader(dataset=validation_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=validation_batch_size,\n",
    "                                          shuffle=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VxI3NAsuWzyk",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This code is provided for Deep Learning class (CS 482/682) Homework 6 practice.\n",
    "# The network structure is a simplified U-net. You need to finish the last layers\n",
    "# @Copyright Cong Gao, the Johns Hopkins University, cgao11@jhu.edu\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as functional\n",
    "import numpy as np\n",
    "\n",
    "def add_conv_stage(dim_in, dim_out, kernel_size=3, stride=1, padding=1, bias=True, useBN=False):\n",
    "  if useBN:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.BatchNorm2d(dim_out),\n",
    "      nn.LeakyReLU(0.1)\n",
    "    )\n",
    "  else:\n",
    "    return nn.Sequential(\n",
    "      nn.Conv2d(dim_in, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU(),\n",
    "      nn.Conv2d(dim_out, dim_out, kernel_size=kernel_size, stride=stride, padding=padding, bias=bias),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "\n",
    "def add_merge_stage(ch_coarse, ch_fine, in_coarse, in_fine, upsample):\n",
    "  conv = nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  torch.cat(conv, in_fine)\n",
    "\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False)\n",
    "  )\n",
    "  upsample(in_coarse)\n",
    "\n",
    "def upsample(ch_coarse, ch_fine):\n",
    "  return nn.Sequential(\n",
    "    nn.ConvTranspose2d(ch_coarse, ch_fine, 4, 2, 1, bias=False),\n",
    "    nn.ReLU()\n",
    "  )\n",
    "\n",
    "class unet(nn.Module):\n",
    "  def __init__(self, useBN=True):\n",
    "    super(unet, self).__init__()\n",
    "    # Downgrade stages\n",
    "    self.conv1   = add_conv_stage(3, 32, useBN=useBN)\n",
    "    self.conv2   = add_conv_stage(32, 64, useBN=useBN)\n",
    "    self.conv3   = add_conv_stage(64, 128, useBN=useBN)\n",
    "    self.conv4   = add_conv_stage(128, 256, useBN=useBN)\n",
    "    # Upgrade stages\n",
    "    self.conv4m = add_conv_stage(512, 256, useBN=useBN)\n",
    "    self.conv3m = add_conv_stage(256, 128, useBN=useBN)\n",
    "    self.conv2m = add_conv_stage(128,  64, useBN=useBN)\n",
    "    self.conv1m = add_conv_stage( 64,  32, useBN=useBN)\n",
    "    # Maxpool\n",
    "    self.max_pool = nn.MaxPool2d(2)\n",
    "    # Upsample layers\n",
    "    self.upsample54 = upsample(512, 256)\n",
    "    self.upsample43 = upsample(256, 128)\n",
    "    self.upsample32 = upsample(128,  64)\n",
    "    self.upsample21 = upsample(64 ,  32)\n",
    "    ## weight initialization\n",
    "    for m in self.modules():\n",
    "      if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n",
    "        if m.bias is not None:\n",
    "          m.bias.data.zero_()\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    self.conv_last = nn.Conv2d(32, 8, 1)\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    conv1_out = self.conv1(x)\n",
    "    conv2_out = self.conv2(self.max_pool(conv1_out))\n",
    "    conv3_out = self.conv3(self.max_pool(conv2_out))\n",
    "    conv4_out = self.conv4(self.max_pool(conv3_out))\n",
    "\n",
    "    conv4m_out_ = torch.cat((self.upsample43(conv4_out), conv3_out), 1)\n",
    "    conv3m_out = self.conv3m(conv4m_out_)\n",
    "\n",
    "    conv3m_out_ = torch.cat((self.upsample32(conv3m_out), conv2_out), 1)\n",
    "    conv2m_out = self.conv2m(conv3m_out_)\n",
    "\n",
    "    conv2m_out_ = torch.cat((self.upsample21(conv2m_out), conv1_out), 1)\n",
    "    conv1m_out = self.conv1m(conv2m_out_)\n",
    "\n",
    "    ## Design your last layer & activations\n",
    "    out = self.conv_last(conv1m_out)\n",
    "    out = torch.sigmoid(out)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8OrYRo_Ew0d2"
   },
   "outputs": [],
   "source": [
    "def dice_loss(output, labels):\n",
    "  output = output.contiguous()\n",
    "  labels = labels.contiguous()\n",
    "  \n",
    "  tp = (output*labels).sum(dim=2).sum(dim=2)\n",
    "  tpfp = output.sum(dim=2).sum(dim=2)\n",
    "  tpfn = labels.sum(dim=2).sum(dim=2)\n",
    "  loss = (1 - ( (2.*tp + 1e-7) / (tpfp+tpfn+1e-7) ) )\n",
    "  \n",
    "  return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2081
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2015247,
     "status": "ok",
     "timestamp": 1555109119568,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "ohneYiithP69",
    "outputId": "2269512d-5c5a-4d23-ecdb-ee2d7ef724ac",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Started!\n",
      "\n",
      "EPOCH 1 of 1000\n",
      "\n",
      "Training Loss: 0.8814\n",
      "1m 14s\n",
      "Validation Loss: 0.8405\n",
      "0m 38s\n",
      "\n",
      "EPOCH 2 of 1000\n",
      "\n",
      "Training Loss: 0.7534\n",
      "2m 8s\n",
      "Validation Loss: 0.6218\n",
      "0m 35s\n",
      "\n",
      "EPOCH 3 of 1000\n",
      "\n",
      "Training Loss: 0.6710\n",
      "1m 33s\n",
      "Validation Loss: 0.6215\n",
      "0m 35s\n",
      "\n",
      "EPOCH 4 of 1000\n",
      "\n",
      "Training Loss: 0.6714\n",
      "1m 29s\n",
      "Validation Loss: 0.6215\n",
      "0m 36s\n",
      "\n",
      "EPOCH 5 of 1000\n",
      "\n",
      "Training Loss: 0.6568\n",
      "1m 21s\n",
      "Validation Loss: 0.6215\n",
      "0m 36s\n",
      "\n",
      "EPOCH 6 of 1000\n",
      "\n",
      "Training Loss: 0.6707\n",
      "1m 24s\n",
      "Validation Loss: 0.6215\n",
      "0m 53s\n",
      "\n",
      "EPOCH 7 of 1000\n",
      "\n",
      "Training Loss: 0.6683\n",
      "1m 10s\n",
      "Validation Loss: 0.6215\n",
      "0m 36s\n",
      "\n",
      "EPOCH 8 of 1000\n",
      "\n",
      "Training Loss: 0.6424\n",
      "1m 18s\n",
      "Validation Loss: 0.6215\n",
      "0m 36s\n",
      "\n",
      "EPOCH 9 of 1000\n",
      "\n",
      "Training Loss: 0.6827\n",
      "1m 7s\n",
      "Validation Loss: 0.6215\n",
      "0m 36s\n",
      "\n",
      "EPOCH 10 of 1000\n",
      "\n",
      "Training Loss: 0.6560\n",
      "1m 8s\n",
      "Validation Loss: 0.6215\n",
      "0m 48s\n",
      "\n",
      "EPOCH 11 of 1000\n",
      "\n",
      "Training Loss: 0.6848\n",
      "2m 3s\n",
      "Validation Loss: 0.6215\n",
      "0m 59s\n",
      "\n",
      "EPOCH 12 of 1000\n",
      "\n",
      "Training Loss: 0.6541\n",
      "1m 52s\n",
      "Validation Loss: 0.6215\n",
      "0m 52s\n",
      "\n",
      "EPOCH 13 of 1000\n",
      "\n",
      "Training Loss: 0.6697\n",
      "1m 38s\n",
      "Validation Loss: 0.6215\n",
      "0m 50s\n",
      "\n",
      "EPOCH 14 of 1000\n",
      "\n",
      "Training Loss: 0.6680\n",
      "1m 35s\n",
      "Validation Loss: 0.6215\n",
      "0m 50s\n",
      "\n",
      "EPOCH 15 of 1000\n",
      "\n",
      "Training Loss: 0.6433\n",
      "1m 39s\n",
      "Validation Loss: 0.6215\n",
      "0m 58s\n",
      "The validation loss converges\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuaRhoZRSyiUNC6WUUi5pWCillHLp/wP2C/GaAahR/gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = unet();\n",
    "\n",
    "import time\n",
    "import copy\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "print(\"Training Started!\")\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "converge_epoch = []\n",
    "for epoch in range(num_epochs):\n",
    "    ########################### Training #####################################\n",
    "    print(\"\\nEPOCH \" +str(epoch+1)+\" of \"+str(num_epochs)+\"\\n\")\n",
    "    # Please design your own training section\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "    for _, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "\n",
    "        ### Data Augmentation\n",
    "        i_ver = copy.deepcopy(images)  ## image vertical flip\n",
    "        i_hor = copy.deepcopy(images)  ## image horizontal flip\n",
    "        v_ver = copy.deepcopy(labels)  ## labels vertical flip\n",
    "        v_hor = copy.deepcopy(labels)  ## labels horizontal flip\n",
    "\n",
    "        for i in range(train_batch_size):\n",
    "            for p in range(3):\n",
    "                i_ver[i][p] = torch.from_numpy(np.flipud(images[i][p]).copy())\n",
    "                i_hor[i][p] = torch.from_numpy(np.fliplr(images[i][p]).copy())\n",
    "            for q in range(8):\n",
    "                v_ver[i][q] = torch.from_numpy(np.flipud(labels[i][q]).copy())\n",
    "                v_hor[i][q] = torch.from_numpy(np.fliplr(labels[i][q]).copy())\n",
    "        \n",
    "        # Regular Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "        # Vertical Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(i_ver)\n",
    "        loss = dice_loss(outputs, v_ver)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "        \n",
    "        # Horizontal Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(i_hor)\n",
    "        loss = dice_loss(outputs, v_hor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.data.item())\n",
    "\n",
    "        break\n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Training Loss: %.4f\" % (mean_loss))\n",
    "    train_losses.append(mean_loss)\n",
    "    converge_epoch.append(epoch)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "    ########################### Validation #####################################\n",
    "    # Please design your own validation section\n",
    "    model.eval()\n",
    "    since = time.time()\n",
    "    losses=[]\n",
    "\n",
    "    for (images, labels) in validation_loader:\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels.float())\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = dice_loss(outputs, labels)\n",
    "        losses.append(loss.data.item())\n",
    "    \n",
    "    ### Average Batch Loss\n",
    "    mean_loss = sum(losses)/len(losses)\n",
    "    print(\"Validation Loss: %.4f\" % (mean_loss))\n",
    "    val_losses.append(mean_loss)\n",
    "    \n",
    "    ### Timing\n",
    "    time_elapsed = time.time() - since\n",
    "    print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    ### Early Stopping\n",
    "    if epoch > 13 and abs(mean_loss - val_losses[epoch-1]) <= 0.001:\n",
    "        print('The validation loss converges')\n",
    "        break\n",
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1028,
     "status": "error",
     "timestamp": 1555103163749,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "gfRS-jMeO7rK",
    "outputId": "5c05306d-fe86-421d-a140-0670e3493ac6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a2d5d68f2ea4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverge_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"training loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverge_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"validation loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoches'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(converge_epoch, train_losses, label = \"training loss\")\n",
    "plt.plot(converge_epoch, val_losses, label = \"validation loss\")\n",
    "plt.xlabel('epoches')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 63363,
     "status": "ok",
     "timestamp": 1555109319138,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "yusfwz_ib5DF",
    "outputId": "7ef40d28-2e98-4d84-ccab-b7740763f63c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing performance - DICE score: 0.3584\n",
      "1m 3s\n"
     ]
    }
   ],
   "source": [
    "########################### Testing #####################################\n",
    "# Please design your own validation section\n",
    "model.eval()\n",
    "since = time.time()\n",
    "losses=[]\n",
    "\n",
    "for (images, labels) in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    labels = Variable(labels.float())\n",
    "\n",
    "    outputs = model(images)\n",
    "    loss = dice_loss(outputs, labels)\n",
    "    losses.append(loss.data.item())\n",
    "\n",
    "### Average Batch Loss\n",
    "mean_loss = sum(losses)/len(losses)\n",
    "print(\"Testing performance - DICE score: %.4f\" % (1-mean_loss))\n",
    "\n",
    "### Timing\n",
    "time_elapsed = time.time() - since\n",
    "print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GgqA56p3vBoT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Xi_Wang_HW6_Q1c.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
