{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nwcq3KG1BMBa"
   },
   "outputs": [],
   "source": [
    "########## (a) ##########\n",
    "# This code is used for JHU CS 482/682: Deep Learning 2019 Spring Homework 4\n",
    "# Copyright @ Johns Hopkins University, Cong Gao, cgao11@jhu.edu\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# IMPORTANT: This function is used for de-normalizing image to original domain,\n",
    "# please use this if you want to visualize/recover your output result\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "# These hyperparameters can be changed\n",
    "num_epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# This is a recommended normalization method. You can design your own\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))\n",
    "])\n",
    "\n",
    "# Dataset wiill be downloaded to './data' folder\n",
    "dataset = FashionMNIST('./data', transform=img_transform, download=True)\n",
    "train_dataset = FashionMNIST('./data', train=True, transform=img_transform, download=True)\n",
    "test_dataset = FashionMNIST('./data', train=False, transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True);\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True);\n",
    "\n",
    "# This is our provided network autoencoder class, you are encouraged to change\n",
    "# the structure settings\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # make sure you keep this layer during your autoencoder training, this\n",
    "        # will be used for Q3-(c) fully connected layer\n",
    "        self.linear = nn.Linear(32,10)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # IMPORTANT: in Q3-(c), please delete the above decoder layer, and use\n",
    "        # the linear layer to build fully-connection layers.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 480568,
     "status": "ok",
     "timestamp": 1552768069160,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "fp5K9hAB38jV",
    "outputId": "73ccc1bf-9fb5-4d28-b6a2-31cd6f8716c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.1142\n",
      "Epoch: 2\n",
      "Training Loss: 0.1048\n",
      "Epoch: 3\n",
      "Training Loss: 0.0835\n",
      "Epoch: 4\n",
      "Training Loss: 0.0928\n",
      "Epoch: 5\n",
      "Training Loss: 0.0888\n",
      "Epoch: 6\n",
      "Training Loss: 0.0796\n",
      "Epoch: 7\n",
      "Training Loss: 0.0843\n",
      "Epoch: 8\n",
      "Training Loss: 0.0810\n",
      "Epoch: 9\n",
      "Training Loss: 0.0754\n",
      "Epoch: 10\n",
      "Training Loss: 0.0707\n",
      "Epoch: 11\n",
      "Training Loss: 0.0717\n",
      "Epoch: 12\n",
      "Training Loss: 0.0760\n",
      "Epoch: 13\n",
      "Training Loss: 0.0770\n",
      "Epoch: 14\n",
      "Training Loss: 0.0711\n",
      "Epoch: 15\n",
      "Training Loss: 0.0804\n",
      "Epoch: 16\n",
      "Training Loss: 0.0679\n",
      "Epoch: 17\n",
      "Training Loss: 0.0649\n",
      "Epoch: 18\n",
      "Training Loss: 0.0677\n",
      "Epoch: 19\n",
      "Training Loss: 0.0741\n",
      "Epoch: 20\n",
      "Training Loss: 0.0710\n"
     ]
    }
   ],
   "source": [
    "########## (a) ##########\n",
    "model = autoencoder()\n",
    "if torch.cuda.is_available(): #use gpu if available\n",
    "    model.cuda()\n",
    "\n",
    "# In Q3-(c), you need to load your model using the following command\n",
    "#model.load_state_dict(torch.load('./yourmodel.pth'))\n",
    "\n",
    "# Setting requires_grad to False will 'freeze' the parameters during training\n",
    "#model.encoder.requires_grad = False\n",
    "\n",
    "# This is a recommended optimizer setting\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training & Validation\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        images = data[0]\n",
    "        images = Variable(images.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: %d\" % (epoch+1))\n",
    "    print(\"Training Loss: %.4f\" % (loss.data.item()))\n",
    "\n",
    "# # This is used to save your model, please remember to include it\n",
    "torch.save(model.state_dict(), './yourmodel.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 356208,
     "status": "ok",
     "timestamp": 1552768069803,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "7xnx1W9uxNVR",
    "outputId": "c25e3a4c-dc0d-405d-e556-564d2b712d42"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncZ8jd36X8gIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## (a) ##########\n",
    "### Feature Map\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kernel = model.encoder[0].weight.data.numpy()\n",
    "figure = plt.figure(figsize=(4,4))\n",
    "for i in range(len(kernel)):\n",
    "    plot = figure.add_subplot(4,4, i+1)\n",
    "    plot.imshow(kernel[i][0])\n",
    "    plot.axis('off')\n",
    "    plot.set_xticklabels([])\n",
    "    plot.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1203513,
     "status": "ok",
     "timestamp": 1552768917921,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "yXuGnfUJ6far",
    "outputId": "b8a6c46b-c935-4286-91ab-2794fc83c8e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.3223\n",
      "Epoch: 2\n",
      "Training Loss: 0.2495\n",
      "Epoch: 3\n",
      "Training Loss: 0.2465\n",
      "Epoch: 4\n",
      "Training Loss: 0.2213\n",
      "Epoch: 5\n",
      "Training Loss: 0.2268\n",
      "Epoch: 6\n",
      "Training Loss: 0.2242\n",
      "Epoch: 7\n",
      "Training Loss: 0.2206\n",
      "Epoch: 8\n",
      "Training Loss: 0.2047\n",
      "Epoch: 9\n",
      "Training Loss: 0.1943\n",
      "Epoch: 10\n",
      "Training Loss: 0.1996\n",
      "Epoch: 11\n",
      "Training Loss: 0.2321\n",
      "Epoch: 12\n",
      "Training Loss: 0.1949\n",
      "Epoch: 13\n",
      "Training Loss: 0.2114\n",
      "Epoch: 14\n",
      "Training Loss: 0.2006\n",
      "Epoch: 15\n",
      "Training Loss: 0.1923\n",
      "Epoch: 16\n",
      "Training Loss: 0.1902\n",
      "Epoch: 17\n",
      "Training Loss: 0.1787\n",
      "Epoch: 18\n",
      "Training Loss: 0.2017\n",
      "Epoch: 19\n",
      "Training Loss: 0.1847\n",
      "Epoch: 20\n",
      "Training Loss: 0.2050\n"
     ]
    }
   ],
   "source": [
    "########## (b) ##########\n",
    "from imgaug import augmenters as iaa\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout(p=(0,0.2)),\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255)),\n",
    "    iaa.SaltAndPepper(0.05)\n",
    "])\n",
    "\n",
    "\n",
    "model = autoencoder()\n",
    "if torch.cuda.is_available(): #use gpu if available\n",
    "    model.cuda()\n",
    "\n",
    "# In Q3-(c), you need to load your model using the following command\n",
    "#model.load_state_dict(torch.load('./yourmodel.pth'))\n",
    "\n",
    "# Setting requires_grad to False will 'freeze' the parameters during training\n",
    "#model.encoder.requires_grad = False\n",
    "\n",
    "# This is a recommended optimizer setting\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training & Validation\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        images = data[0]\n",
    "        images = Variable(images.float())\n",
    "        ### Data Augmentation\n",
    "        images_aug = seq.augment_images(images.numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.Tensor(images_aug))\n",
    "\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: %d\" % (epoch+1))\n",
    "    print(\"Training Loss: %.4f\" % (loss.data.item()))\n",
    "\n",
    "# # This is used to save your model, please remember to include it\n",
    "torch.save(model.state_dict(), './yourmodel_b.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1203552,
     "status": "ok",
     "timestamp": 1552768918490,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "KRw8fn-862RK",
    "outputId": "0978a397-c225-40d9-b52f-147ecc4e8517"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## (b) ##########\n",
    "### Feature Map\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kernel = model.encoder[0].weight.data.numpy()\n",
    "figure = plt.figure(figsize=(4,4))\n",
    "for i in range(len(kernel)):\n",
    "    plot = figure.add_subplot(4,4, i+1)\n",
    "    plot.imshow(kernel[i][0])\n",
    "    plot.axis('off')\n",
    "    plot.set_xticklabels([])\n",
    "    plot.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1391040,
     "status": "ok",
     "timestamp": 1552773935389,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "H_sCus9--5Lu",
    "outputId": "8b6cff06-8e2f-48a6-fccc-e62aa20c3d7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.8335\n",
      "Epoch: 2\n",
      "Training Loss: 1.0818\n",
      "Epoch: 3\n",
      "Training Loss: 0.5929\n",
      "Epoch: 4\n",
      "Training Loss: 0.5515\n",
      "Epoch: 5\n",
      "Training Loss: 0.6359\n",
      "Epoch: 6\n",
      "Training Loss: 0.6711\n",
      "Epoch: 7\n",
      "Training Loss: 0.5057\n",
      "Epoch: 8\n",
      "Training Loss: 0.5901\n",
      "Epoch: 9\n",
      "Training Loss: 0.5445\n",
      "Epoch: 10\n",
      "Training Loss: 0.6924\n",
      "Epoch: 11\n",
      "Training Loss: 0.5711\n",
      "Epoch: 12\n",
      "Training Loss: 0.4626\n",
      "Epoch: 13\n",
      "Training Loss: 0.4852\n",
      "Epoch: 14\n",
      "Training Loss: 0.4032\n",
      "Epoch: 15\n",
      "Training Loss: 0.3767\n",
      "Epoch: 16\n",
      "Training Loss: 0.6782\n",
      "Epoch: 17\n",
      "Training Loss: 0.6788\n",
      "Epoch: 18\n",
      "Training Loss: 0.4345\n",
      "Epoch: 19\n",
      "Training Loss: 0.5275\n",
      "Epoch: 20\n",
      "Training Loss: 0.4503\n",
      "Epoch: 21\n",
      "Training Loss: 0.5663\n",
      "Epoch: 22\n",
      "Training Loss: 0.4657\n",
      "Epoch: 23\n",
      "Training Loss: 0.3364\n",
      "Epoch: 24\n",
      "Training Loss: 0.4288\n",
      "Epoch: 25\n",
      "Training Loss: 0.4713\n",
      "Epoch: 26\n",
      "Training Loss: 0.5590\n",
      "Epoch: 27\n",
      "Training Loss: 0.4061\n",
      "Epoch: 28\n",
      "Training Loss: 0.4663\n",
      "Epoch: 29\n",
      "Training Loss: 0.5313\n",
      "Epoch: 30\n",
      "Training Loss: 0.5150\n",
      "Epoch: 31\n",
      "Training Loss: 0.4189\n",
      "Epoch: 32\n",
      "Training Loss: 0.4417\n",
      "Epoch: 33\n",
      "Training Loss: 0.4561\n",
      "Epoch: 34\n",
      "Training Loss: 0.3568\n",
      "Epoch: 35\n",
      "Training Loss: 0.3655\n",
      "Epoch: 36\n",
      "Training Loss: 0.5322\n",
      "Epoch: 37\n",
      "Training Loss: 0.4169\n",
      "Epoch: 38\n",
      "Training Loss: 0.3834\n",
      "Epoch: 39\n",
      "Training Loss: 0.4723\n",
      "Epoch: 40\n",
      "Training Loss: 0.3779\n",
      "Epoch: 41\n",
      "Training Loss: 0.3280\n",
      "Epoch: 42\n",
      "Training Loss: 0.4822\n",
      "Epoch: 43\n",
      "Training Loss: 0.3955\n",
      "Epoch: 44\n",
      "Training Loss: 0.5697\n",
      "Epoch: 45\n",
      "Training Loss: 0.4000\n",
      "Epoch: 46\n",
      "Training Loss: 0.3451\n",
      "Epoch: 47\n",
      "Training Loss: 0.5090\n",
      "Epoch: 48\n",
      "Training Loss: 0.2602\n",
      "Epoch: 49\n",
      "Training Loss: 0.4515\n",
      "Epoch: 50\n",
      "Training Loss: 0.3686\n",
      "Epoch: 51\n",
      "Training Loss: 0.3493\n",
      "Epoch: 52\n",
      "Training Loss: 0.4443\n",
      "Epoch: 53\n",
      "Training Loss: 0.2631\n",
      "Epoch: 54\n",
      "Training Loss: 0.5135\n",
      "Epoch: 55\n",
      "Training Loss: 0.4278\n",
      "Epoch: 56\n",
      "Training Loss: 0.4879\n",
      "Epoch: 57\n",
      "Training Loss: 0.2378\n",
      "Epoch: 58\n",
      "Training Loss: 0.3012\n",
      "Epoch: 59\n",
      "Training Loss: 0.4206\n",
      "Epoch: 60\n",
      "Training Loss: 0.4653\n",
      "Epoch: 61\n",
      "Training Loss: 0.6126\n",
      "Epoch: 62\n",
      "Training Loss: 0.4373\n",
      "Epoch: 63\n",
      "Training Loss: 0.3638\n",
      "Epoch: 64\n",
      "Training Loss: 0.3899\n",
      "Epoch: 65\n",
      "Training Loss: 0.3928\n",
      "Epoch: 66\n",
      "Training Loss: 0.3012\n",
      "Epoch: 67\n",
      "Training Loss: 0.3686\n",
      "Epoch: 68\n",
      "Training Loss: 0.5021\n",
      "Epoch: 69\n",
      "Training Loss: 0.3172\n",
      "Epoch: 70\n",
      "Training Loss: 0.3984\n",
      "Epoch: 71\n",
      "Training Loss: 0.3065\n",
      "Epoch: 72\n",
      "Training Loss: 0.3226\n",
      "Epoch: 73\n",
      "Training Loss: 0.3508\n",
      "Epoch: 74\n",
      "Training Loss: 0.3088\n",
      "Epoch: 75\n",
      "Training Loss: 0.4982\n",
      "Epoch: 76\n",
      "Training Loss: 0.4379\n",
      "Epoch: 77\n",
      "Training Loss: 0.4239\n",
      "Epoch: 78\n",
      "Training Loss: 0.4155\n",
      "Epoch: 79\n",
      "Training Loss: 0.3876\n",
      "Epoch: 80\n",
      "Training Loss: 0.3182\n",
      "Epoch: 81\n",
      "Training Loss: 0.4307\n",
      "Epoch: 82\n",
      "Training Loss: 0.3548\n",
      "Epoch: 83\n",
      "Training Loss: 0.4572\n",
      "Epoch: 84\n",
      "Training Loss: 0.3379\n",
      "Epoch: 85\n",
      "Training Loss: 0.3799\n",
      "Epoch: 86\n",
      "Training Loss: 0.5766\n",
      "Epoch: 87\n",
      "Training Loss: 0.3697\n",
      "Epoch: 88\n",
      "Training Loss: 0.3466\n",
      "Epoch: 89\n",
      "Training Loss: 0.2861\n",
      "Epoch: 90\n",
      "Training Loss: 0.3942\n",
      "Epoch: 91\n",
      "Training Loss: 0.4625\n",
      "Epoch: 92\n",
      "Training Loss: 0.3913\n",
      "Epoch: 93\n",
      "Training Loss: 0.3078\n",
      "Epoch: 94\n",
      "Training Loss: 0.3271\n",
      "Epoch: 95\n",
      "Training Loss: 0.4344\n",
      "Epoch: 96\n",
      "Training Loss: 0.3507\n",
      "Epoch: 97\n",
      "Training Loss: 0.3451\n",
      "Epoch: 98\n",
      "Training Loss: 0.2331\n",
      "Epoch: 99\n",
      "Training Loss: 0.4032\n",
      "Epoch: 100\n",
      "Training Loss: 0.3656\n"
     ]
    }
   ],
   "source": [
    "########## (c) ##########\n",
    "# This is our provided network autoencoder class, you are encouraged to change\n",
    "# the structure settings\n",
    "class autoencoder3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder3, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # make sure you keep this layer during your autoencoder training, this\n",
    "        # will be used for Q3-(c) fully connected layer\n",
    "        self.linear = nn.Linear(32,10)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        # IMPORTANT: in Q3-(c), please delete the above decoder layer, and use\n",
    "        # the linear layer to build fully-connection layers.\n",
    "        return x\n",
    "      \n",
    "model = autoencoder3()\n",
    "if torch.cuda.is_available(): #use gpu if available\n",
    "    model.cuda()\n",
    "\n",
    "# In Q3-(c), you need to load your model using the following command\n",
    "model.load_state_dict(torch.load('./yourmodel_b.pth'))\n",
    "\n",
    "# Setting requires_grad to False will 'freeze' the parameters during training\n",
    "model.encoder.requires_grad = False\n",
    "\n",
    "# This is a recommended optimizer setting\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training & Validation\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: %d\" % (epoch+1))\n",
    "    print(\"Training Loss: %.4f\" % (loss.data.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2132,
     "status": "ok",
     "timestamp": 1552774067955,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "3oh30QGKA-bi",
    "outputId": "f32ff7b3-eb8a-485d-f518-db436f4aebdd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is: 84.86%\n"
     ]
    }
   ],
   "source": [
    "########## (c) ##########\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_num = 0\n",
    "for (images, labels) in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    outputs = model(images)\n",
    "    a, predicted = torch.max(outputs.data, 1)\n",
    "    test_num += len(labels)\n",
    "    test_correct += (predicted == labels).sum().item()\n",
    "print(\"Test Accuracy is: \" + str(test_correct/float(test_num)*100) + \"%\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Xi_Wang_HW4_Q3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
