{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Nwcq3KG1BMBa"
   },
   "outputs": [],
   "source": [
    "########## (a) ##########\n",
    "# This code is used for JHU CS 482/682: Deep Learning 2019 Spring Homework 4\n",
    "# Copyright @ Johns Hopkins University, Cong Gao, cgao11@jhu.edu\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import FashionMNIST\n",
    "\n",
    "# IMPORTANT: This function is used for de-normalizing image to original domain,\n",
    "# please use this if you want to visualize/recover your output result\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 28, 28)\n",
    "    return x\n",
    "\n",
    "# These hyperparameters can be changed\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# This is a recommended normalization method. You can design your own\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, ), (0.5, ))\n",
    "])\n",
    "\n",
    "# Dataset wiill be downloaded to './data' folder\n",
    "dataset = FashionMNIST('./data', transform=img_transform, download=True)\n",
    "train_dataset = FashionMNIST('./data', train=True, transform=img_transform, download=True)\n",
    "test_dataset = FashionMNIST('./data', train=False, transform=img_transform, download=True)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True);\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True);\n",
    "\n",
    "# This is our provided network autoencoder class, you are encouraged to change\n",
    "# the structure settings\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=1, padding=1),  # b, 16, 28, 28\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1),  # b, 8, 27, 27\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 14, 14\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 7, 7\n",
    "            nn.Conv2d(8, 8, 3, stride=3, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 8, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 16, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # make sure you keep this layer during your autoencoder training, this\n",
    "        # will be used for Q3-(c) fully connected layer\n",
    "        self.linear = nn.Linear(32,10)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        # IMPORTANT: in Q3-(c), please delete the above decoder layer, and use\n",
    "        # the linear layer to build fully-connection layers.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1812234,
     "status": "ok",
     "timestamp": 1552780177035,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "fp5K9hAB38jV",
    "outputId": "b02acae0-4e3b-4478-ad02-febd4bbe81de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.1003\n",
      "Epoch: 2\n",
      "Training Loss: 0.0975\n",
      "Epoch: 3\n",
      "Training Loss: 0.0831\n",
      "Epoch: 4\n",
      "Training Loss: 0.0802\n",
      "Epoch: 5\n",
      "Training Loss: 0.0685\n",
      "Epoch: 6\n",
      "Training Loss: 0.0698\n",
      "Epoch: 7\n",
      "Training Loss: 0.0656\n",
      "Epoch: 8\n",
      "Training Loss: 0.0667\n",
      "Epoch: 9\n",
      "Training Loss: 0.0737\n",
      "Epoch: 10\n",
      "Training Loss: 0.0715\n",
      "Epoch: 11\n",
      "Training Loss: 0.0664\n",
      "Epoch: 12\n",
      "Training Loss: 0.0707\n",
      "Epoch: 13\n",
      "Training Loss: 0.0696\n",
      "Epoch: 14\n",
      "Training Loss: 0.0684\n",
      "Epoch: 15\n",
      "Training Loss: 0.0590\n",
      "Epoch: 16\n",
      "Training Loss: 0.0649\n",
      "Epoch: 17\n",
      "Training Loss: 0.0704\n",
      "Epoch: 18\n",
      "Training Loss: 0.0771\n",
      "Epoch: 19\n",
      "Training Loss: 0.0722\n",
      "Epoch: 20\n",
      "Training Loss: 0.0728\n"
     ]
    }
   ],
   "source": [
    "########## (a) ##########\n",
    "model = autoencoder()\n",
    "if torch.cuda.is_available(): #use gpu if available\n",
    "    model.cuda()\n",
    "\n",
    "# In Q3-(c), you need to load your model using the following command\n",
    "#model.load_state_dict(torch.load('./yourmodel.pth'))\n",
    "\n",
    "# Setting requires_grad to False will 'freeze' the parameters during training\n",
    "#model.encoder.requires_grad = False\n",
    "\n",
    "# This is a recommended optimizer setting\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training & Validation\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        images = data[0]\n",
    "        images = Variable(images.float())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: %d\" % (epoch+1))\n",
    "    print(\"Training Loss: %.4f\" % (loss.data.item()))\n",
    "\n",
    "# # This is used to save your model, please remember to include it\n",
    "torch.save(model.state_dict(), './yourmodel.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 788,
     "status": "ok",
     "timestamp": 1552780386194,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "7xnx1W9uxNVR",
    "outputId": "3445d08e-8067-4ab2-ca8e-e3841a46fb42"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXnEKCWDMFSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## (a) ##########\n",
    "### Feature Map\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kernel = model.encoder[0].weight.data.numpy()\n",
    "figure = plt.figure(figsize=(4,4))\n",
    "for i in range(len(kernel)):\n",
    "    plot = figure.add_subplot(4,4, i+1)\n",
    "    plot.imshow(kernel[i][0])\n",
    "    plot.axis('off')\n",
    "    plot.set_xticklabels([])\n",
    "    plot.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 916702,
     "status": "ok",
     "timestamp": 1552781371934,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "yXuGnfUJ6far",
    "outputId": "95cd502a-f589-4bcf-950b-87da62de8ea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.2001\n",
      "Epoch: 2\n",
      "Training Loss: 0.2167\n",
      "Epoch: 3\n",
      "Training Loss: 0.2117\n",
      "Epoch: 4\n",
      "Training Loss: 0.2022\n",
      "Epoch: 5\n",
      "Training Loss: 0.1920\n",
      "Epoch: 6\n",
      "Training Loss: 0.1829\n",
      "Epoch: 7\n",
      "Training Loss: 0.1617\n",
      "Epoch: 8\n",
      "Training Loss: 0.1658\n",
      "Epoch: 9\n",
      "Training Loss: 0.1693\n",
      "Epoch: 10\n",
      "Training Loss: 0.1623\n"
     ]
    }
   ],
   "source": [
    "########## (b) ##########\n",
    "from imgaug import augmenters as iaa\n",
    "seq = iaa.Sequential([\n",
    "    iaa.Dropout(p=(0,0.2)),\n",
    "    iaa.AdditiveGaussianNoise(loc=0, scale=(0.0, 0.05*255)),\n",
    "    iaa.SaltAndPepper(0.05)\n",
    "])\n",
    "\n",
    "\n",
    "model = autoencoder()\n",
    "if torch.cuda.is_available(): #use gpu if available\n",
    "    model.cuda()\n",
    "\n",
    "# In Q3-(c), you need to load your model using the following command\n",
    "#model.load_state_dict(torch.load('./yourmodel.pth'))\n",
    "\n",
    "# Setting requires_grad to False will 'freeze' the parameters during training\n",
    "#model.encoder.requires_grad = False\n",
    "\n",
    "# This is a recommended optimizer setting\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Training & Validation\n",
    "for epoch in range(num_epochs):\n",
    "    for data in dataloader:\n",
    "        images = data[0]\n",
    "        images = Variable(images.float())\n",
    "        ### Data Augmentation\n",
    "        images_aug = seq.augment_images(images.numpy())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(torch.Tensor(images_aug))\n",
    "\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: %d\" % (epoch+1))\n",
    "    print(\"Training Loss: %.4f\" % (loss.data.item()))\n",
    "\n",
    "# # This is used to save your model, please remember to include it\n",
    "torch.save(model.state_dict(), './yourmodel_b.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 912410,
     "status": "ok",
     "timestamp": 1552781372612,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "KRw8fn-862RK",
    "outputId": "d025d2b2-a010-4583-dd81-d35462cab0fa"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOwAAADnCAYAAAAdFLrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 288x288 with 16 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "########## (b) ##########\n",
    "### Feature Map\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "kernel = model.encoder[0].weight.data.numpy()\n",
    "figure = plt.figure(figsize=(4,4))\n",
    "for i in range(len(kernel)):\n",
    "    plot = figure.add_subplot(4,4, i+1)\n",
    "    plot.imshow(kernel[i][0])\n",
    "    plot.axis('off')\n",
    "    plot.set_xticklabels([])\n",
    "    plot.set_yticklabels([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937747,
     "status": "ok",
     "timestamp": 1552791441930,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "H_sCus9--5Lu",
    "outputId": "11a6c8a1-c7e9-4972-8583-9189d2ba52d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training Loss: 0.6639\n",
      "Epoch: 2\n",
      "Training Loss: 0.4886\n",
      "Epoch: 3\n",
      "Training Loss: 0.4225\n",
      "Epoch: 4\n",
      "Training Loss: 0.4258\n",
      "Epoch: 5\n",
      "Training Loss: 0.3178\n",
      "Epoch: 6\n",
      "Training Loss: 0.3119\n",
      "Epoch: 7\n",
      "Training Loss: 0.4068\n",
      "Epoch: 8\n",
      "Training Loss: 0.3462\n",
      "Epoch: 9\n",
      "Training Loss: 0.3247\n",
      "Epoch: 10\n",
      "Training Loss: 0.5077\n",
      "Epoch: 11\n",
      "Training Loss: 0.5386\n",
      "Epoch: 12\n",
      "Training Loss: 0.3684\n",
      "Epoch: 13\n",
      "Training Loss: 0.4887\n",
      "Epoch: 14\n",
      "Training Loss: 0.4378\n",
      "Epoch: 15\n",
      "Training Loss: 0.3200\n",
      "Epoch: 16\n",
      "Training Loss: 0.4941\n",
      "Epoch: 17\n",
      "Training Loss: 0.1979\n",
      "Epoch: 18\n",
      "Training Loss: 0.4333\n",
      "Epoch: 19\n",
      "Training Loss: 0.1584\n",
      "Epoch: 20\n",
      "Training Loss: 0.4017\n",
      "Epoch: 21\n",
      "Training Loss: 0.1478\n",
      "Epoch: 22\n",
      "Training Loss: 0.2396\n",
      "Epoch: 23\n",
      "Training Loss: 0.3112\n",
      "Epoch: 24\n",
      "Training Loss: 0.3754\n",
      "Epoch: 25\n",
      "Training Loss: 0.4282\n",
      "Epoch: 26\n",
      "Training Loss: 0.5091\n",
      "Epoch: 27\n",
      "Training Loss: 0.2700\n",
      "Epoch: 28\n",
      "Training Loss: 0.3093\n",
      "Epoch: 29\n",
      "Training Loss: 0.2816\n",
      "Epoch: 30\n",
      "Training Loss: 0.5179\n",
      "Epoch: 31\n",
      "Training Loss: 0.4127\n",
      "Epoch: 32\n",
      "Training Loss: 0.4132\n",
      "Epoch: 33\n",
      "Training Loss: 0.4811\n",
      "Epoch: 34\n",
      "Training Loss: 0.3281\n",
      "Epoch: 35\n",
      "Training Loss: 0.1956\n",
      "Epoch: 36\n",
      "Training Loss: 0.1026\n",
      "Epoch: 37\n",
      "Training Loss: 0.4648\n",
      "Epoch: 38\n",
      "Training Loss: 0.2919\n",
      "Epoch: 39\n",
      "Training Loss: 0.2461\n",
      "Epoch: 40\n",
      "Training Loss: 0.2911\n",
      "Epoch: 41\n",
      "Training Loss: 0.2656\n",
      "Epoch: 42\n",
      "Training Loss: 0.1281\n",
      "Epoch: 43\n",
      "Training Loss: 0.2102\n",
      "Epoch: 44\n",
      "Training Loss: 0.2871\n",
      "Epoch: 45\n",
      "Training Loss: 0.4786\n",
      "Epoch: 46\n",
      "Training Loss: 0.1742\n",
      "Epoch: 47\n",
      "Training Loss: 0.1994\n",
      "Epoch: 48\n",
      "Training Loss: 0.0871\n",
      "Epoch: 49\n",
      "Training Loss: 0.2859\n",
      "Epoch: 50\n",
      "Training Loss: 0.0476\n",
      "Epoch: 51\n",
      "Training Loss: 0.2235\n",
      "Epoch: 52\n",
      "Training Loss: 0.4900\n",
      "Epoch: 53\n",
      "Training Loss: 0.1040\n",
      "Epoch: 54\n",
      "Training Loss: 0.3104\n",
      "Epoch: 55\n",
      "Training Loss: 0.3100\n",
      "Epoch: 56\n",
      "Training Loss: 0.5661\n",
      "Epoch: 57\n",
      "Training Loss: 0.2860\n",
      "Epoch: 58\n",
      "Training Loss: 0.1378\n",
      "Epoch: 59\n",
      "Training Loss: 0.4644\n",
      "Epoch: 60\n",
      "Training Loss: 0.3459\n",
      "Epoch: 61\n",
      "Training Loss: 0.1865\n",
      "Epoch: 62\n",
      "Training Loss: 0.2871\n",
      "Epoch: 63\n",
      "Training Loss: 0.2902\n",
      "Epoch: 64\n",
      "Training Loss: 0.1627\n",
      "Epoch: 65\n",
      "Training Loss: 0.6204\n",
      "Epoch: 66\n",
      "Training Loss: 0.1757\n",
      "Epoch: 67\n",
      "Training Loss: 0.1720\n",
      "Epoch: 68\n",
      "Training Loss: 0.2520\n",
      "Epoch: 69\n",
      "Training Loss: 0.2413\n",
      "Epoch: 70\n",
      "Training Loss: 0.5508\n",
      "Epoch: 71\n",
      "Training Loss: 0.2808\n",
      "Epoch: 72\n",
      "Training Loss: 0.1657\n",
      "Epoch: 73\n",
      "Training Loss: 0.7057\n",
      "Epoch: 74\n",
      "Training Loss: 0.2089\n",
      "Epoch: 75\n",
      "Training Loss: 0.1541\n",
      "Epoch: 76\n",
      "Training Loss: 0.2673\n",
      "Epoch: 77\n",
      "Training Loss: 0.2697\n",
      "Epoch: 78\n",
      "Training Loss: 0.2457\n",
      "Epoch: 79\n",
      "Training Loss: 0.2159\n",
      "Epoch: 80\n",
      "Training Loss: 0.4068\n",
      "Epoch: 81\n",
      "Training Loss: 0.1153\n",
      "Epoch: 82\n",
      "Training Loss: 0.3634\n",
      "Epoch: 83\n",
      "Training Loss: 0.1353\n",
      "Epoch: 84\n",
      "Training Loss: 0.3261\n",
      "Epoch: 85\n",
      "Training Loss: 0.5014\n",
      "Epoch: 86\n",
      "Training Loss: 0.2246\n",
      "Epoch: 87\n",
      "Training Loss: 0.2902\n",
      "Epoch: 88\n",
      "Training Loss: 0.1170\n",
      "Epoch: 89\n",
      "Training Loss: 0.2506\n",
      "Epoch: 90\n",
      "Training Loss: 0.1385\n",
      "Epoch: 91\n",
      "Training Loss: 0.2615\n",
      "Epoch: 92\n",
      "Training Loss: 0.3430\n",
      "Epoch: 93\n",
      "Training Loss: 0.2878\n",
      "Epoch: 94\n",
      "Training Loss: 0.1983\n",
      "Epoch: 95\n",
      "Training Loss: 0.4732\n",
      "Epoch: 96\n",
      "Training Loss: 0.2313\n",
      "Epoch: 97\n",
      "Training Loss: 0.2635\n",
      "Epoch: 98\n",
      "Training Loss: 0.3285\n",
      "Epoch: 99\n",
      "Training Loss: 0.3422\n",
      "Epoch: 100\n",
      "Training Loss: 0.2398\n"
     ]
    }
   ],
   "source": [
    "########## (c) ##########\n",
    "# This is our provided network autoencoder class, you are encouraged to change\n",
    "# the structure settings\n",
    "class autoencoder3(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder3, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=1, padding=1),  # b, 16, 28, 28\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1),  # b, 8, 27, 27\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 14, 14\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # b, 16, 7, 7\n",
    "            nn.Conv2d(8, 8, 3, stride=3, padding=1),  # b, 8, 3, 3\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 8, 3, stride=2),  # b, 16, 5, 5\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 16, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        # make sure you keep this layer during your autoencoder training, this\n",
    "        # will be used for Q3-(c) fully connected layer\n",
    "        self.linear = nn.Linear(32,10)\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = x.reshape(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        # IMPORTANT: in Q3-(c), please delete the above decoder layer, and use\n",
    "        # the linear layer to build fully-connection layers.\n",
    "        return x\n",
    "      \n",
    "model = autoencoder3()\n",
    "if torch.cuda.is_available(): #use gpu if available\n",
    "    model.cuda()\n",
    "\n",
    "# In Q3-(c), you need to load your model using the following command\n",
    "model.load_state_dict(torch.load('./yourmodel_b.pth'))\n",
    "\n",
    "# Setting requires_grad to False will 'freeze' the parameters during training\n",
    "model.encoder.requires_grad = False\n",
    "\n",
    "# This is a recommended optimizer setting\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Training & Validation\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = Variable(images.float())\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    print(\"Epoch: %d\" % (epoch+1))\n",
    "    print(\"Training Loss: %.4f\" % (loss.data.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5366,
     "status": "ok",
     "timestamp": 1552791447293,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "3oh30QGKA-bi",
    "outputId": "ea4f83e6-9b2e-434c-b7fb-9176994c48d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy is: 88.53%\n"
     ]
    }
   ],
   "source": [
    "########## (c) ##########\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_num = 0\n",
    "for (images, labels) in test_loader:\n",
    "    images = Variable(images.float())\n",
    "    outputs = model(images)\n",
    "    a, predicted = torch.max(outputs.data, 1)\n",
    "    test_num += len(labels)\n",
    "    test_correct += (predicted == labels).sum().item()\n",
    "print(\"Test Accuracy is: \" + str(test_correct/float(test_num)*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_M5HJhHZFA7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Xi_Wang_HW4_Q3_Improved.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
