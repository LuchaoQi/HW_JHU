{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 611,
     "status": "ok",
     "timestamp": 1552670475694,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "8JnxRZdFW5Ao",
    "outputId": "c7ed5c0a-fb99-4748-da52-8d8d603f92dd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 385,
     "status": "ok",
     "timestamp": 1552685683335,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "DSz_3al-WzyZ",
    "outputId": "ff6a4785-9b00-4333-8747-ad342b6980b5"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "data = np.load('HW4_data.npy')\n",
    "data[:,2]\n",
    "length = len(data[:,0])\n",
    "train = data[:50000,:]\n",
    "test = data[-10000:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4989,
     "status": "ok",
     "timestamp": 1552689406236,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "VxI3NAsuWzyk",
    "outputId": "6a8765a7-396f-41e3-c3d3-29b743fd95b6",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "########## (a) Manually Setting up MLP ##########\n",
    "dic = {}\n",
    "\n",
    "### Manually Selected Weights\n",
    "for i in range(10):\n",
    "    dic[i] = [0]*2\n",
    "dic[0][0] = np.array([-1,1])\n",
    "dic[0][1] = -5\n",
    "dic[1][0] = np.array([1,2])\n",
    "dic[1][1] = 14\n",
    "dic[2][0] = np.array([1,0])\n",
    "dic[2][1] = 6\n",
    "dic[3][0] = np.array([1,-2])\n",
    "dic[3][1] = -6\n",
    "dic[4][0] = np.array([-1,-1])\n",
    "dic[4][1] = -15\n",
    "dic[5][0] = np.array([-1,0.5])\n",
    "dic[5][1] = -3.5\n",
    "dic[6][0] = np.array([1,1])\n",
    "dic[6][1] = 5\n",
    "dic[7][0] = np.array([1,0])\n",
    "dic[7][1] = 2\n",
    "dic[8][0] = np.array([1,-1])\n",
    "dic[8][1] = -5\n",
    "dic[9][0] = np.array([-1,-0.5])\n",
    "dic[9][1] = -8.5\n",
    "for i in range(10):\n",
    "    dic[i][1] *= 100\n",
    "\n",
    "### Use Manual Model to make predictions\n",
    "ans = [0]*length\n",
    "correct = 0\n",
    "for i in range(length):\n",
    "    x = np.array([data[i][1],data[i][0]])\n",
    "    y1 = 0\n",
    "    y2 = 0\n",
    "    for j in range(5):\n",
    "        y1 += 1*( x.dot(dic[j][0]) - dic[j][1] > 0 )\n",
    "        y2 += 1*( x.dot(dic[j+5][0]) - dic[j+5][1] > 0 )\n",
    "    if y1 >= 5 or y2 >= 5:\n",
    "        ans[i] = 1\n",
    "    if data[i,2] == ans[i]:\n",
    "        correct+= 1\n",
    "print(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 496
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1629859,
     "status": "ok",
     "timestamp": 1552699112381,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "eVm_vt6fxn9V",
    "outputId": "673541c3-9c1d-44b2-f357-a9f63c6c8d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and Test with random initialization round 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tAverage Loss is: [[2.33107402]]\n",
      "\tTrain Accuracy: 82.282%\n",
      "\tAverage Loss is: [[0.65754397]]\n",
      "\tTest Accuracy: 69.92%\n",
      "Train and Test with random initialization round 1:\n",
      "\tAverage Loss is: [[2.33549455]]\n",
      "\tTrain Accuracy: 82.282%\n",
      "\tAverage Loss is: [[0.65702699]]\n",
      "\tTest Accuracy: 69.92%\n",
      "Train and Test with random initialization round 2:\n",
      "\tAverage Loss is: [[2.0577669]]\n",
      "\tTrain Accuracy: 82.282%\n",
      "\tAverage Loss is: [[0.59243162]]\n",
      "\tTest Accuracy: 69.92%\n",
      "Train and Test with random initialization round 3:\n",
      "\tAverage Loss is: [[2.33283494]]\n",
      "\tTrain Accuracy: 82.282%\n",
      "\tAverage Loss is: [[0.65645398]]\n",
      "\tTest Accuracy: 69.92%\n",
      "Train and Test with random initialization round 4:\n",
      "\tAverage Loss is: [[2.33261661]]\n",
      "\tTrain Accuracy: 82.282%\n",
      "\tAverage Loss is: [[0.65657701]]\n",
      "\tTest Accuracy: 69.92%\n"
     ]
    }
   ],
   "source": [
    "########## (b) ##########\n",
    "def sigmoid(f1):\n",
    "    sig = 1/( 1+np.exp(-f1) )\n",
    "    return sig\n",
    "for t in range(5):\n",
    "    print(\"Train and Test with random initialization round \" + str(t) + \":\")\n",
    "\n",
    "    ### Weights and bias Initialization\n",
    "    w1 = np.random.uniform(-2,2,(10,2))\n",
    "    b1 = np.random.uniform(-1500, 1400, (10,1))\n",
    "\n",
    "    w2 = np.full((2,10), 1.0)\n",
    "    b2 = np.full((2,1), 0.0)\n",
    "\n",
    "    w3 = np.full((1,2), 1.0)\n",
    "    b3= 0\n",
    "\n",
    "    ## Number of iterations and stepsize hyperparameter\n",
    "    iter_n = 100\n",
    "    step = 0.1\n",
    "    decay_counter = 0\n",
    "    T_Loss = 0\n",
    "    ## Training\n",
    "    for p in range(iter_n):\n",
    "        decay_counter += 1\n",
    "        if decay_counter == 20:\n",
    "            step*=0.1\n",
    "            decay_counter = 0\n",
    "        correct = 0\n",
    "        for i in range(50000):\n",
    "            x = np.array([data[i][0],data[i][1]])\n",
    "            x = x.reshape(2,1)\n",
    "\n",
    "            f1 = w1.dot(x) + b1 #1x10\n",
    "            sigf1 = sigmoid(f1) #1x10\n",
    "\n",
    "            f2 = w2.dot(sigf1) + b2 #1x2\n",
    "            sigf2 = sigmoid(f2) #1x2\n",
    "\n",
    "            f3 = w3.dot(sigf2) + b3 # C\n",
    "            sigf3 = sigmoid(f3)\n",
    "            y_hat = 1*(sigf3>0.5)\n",
    "\n",
    "            ## Gradient of w3, b3\n",
    "            dsigf3 = -(data[i,2]/sigf3) + (1-data[i,2])/(1-sigf3) # C\n",
    "            df3 = dsigf3 * ( sigf3 * (1-sigf3) ) # C\n",
    "            dw3 = df3 * sigf2.T #1x2\n",
    "            db3 = df3 # C\n",
    "\n",
    "            ## Gradient of w2, b2\n",
    "            dsigf2 = df3 * w3 #1x2\n",
    "            df2 = dsigf2.T * ( sigf2 * (1-sigf2) ) #1x2\n",
    "            dw2 = df2.dot(sigf1.T) #2x10\n",
    "            db2 = df2 #1x2\n",
    "\n",
    "            ## Gradient of w1, b1\n",
    "            dsigf1 = df2.T.dot(w2) #1x10\n",
    "            df1 = dsigf1.T * ( sigf1 * (1-sigf1) ) #10x1\n",
    "            dw1 = df1.dot(x.T) #10x2\n",
    "            db1 = df1\n",
    "\n",
    "            ## BP\n",
    "            w1 -= step*dw1\n",
    "            b1 -= step*db1\n",
    "\n",
    "            w2 -= step*dw2\n",
    "            b2 -= step*db2\n",
    "\n",
    "            w3 -= step*dw3\n",
    "            b3 -= step*db3\n",
    "\n",
    "            if p == iter_n - 1:\n",
    "                y = data[i,2]\n",
    "                T_Loss += -( y*np.log(sigf3) + (1-y)*np.log(1-sigf3) )\n",
    "                if y_hat == data[i,2]:\n",
    "                    correct+=1\n",
    "    print(\"\\tAverage Loss is: \" + str(T_Loss/10000))\n",
    "    print(\"\\tTrain Accuracy: \" + str(correct/50000*100) + \"%\")\n",
    "\n",
    "    ### Testing\n",
    "    test_correct = 0\n",
    "    Loss = 0\n",
    "    for i in range(len(test)):\n",
    "        x = np.array([test[i][0],test[i][1]])\n",
    "        x = x.reshape(2,1)\n",
    "\n",
    "        f1 = w1.dot(x) + b1 #1x10\n",
    "        sigf1 = sigmoid(f1) #1x10\n",
    "\n",
    "        f2 = w2.dot(sigf1) + b2 #1x2\n",
    "        sigf2 = sigmoid(f2) #1x2\n",
    "\n",
    "        f3 = w3.dot(sigf2) + b3 # C\n",
    "        sigf3 = sigmoid(f3)\n",
    "        y_hat = 1*(sigf3>0.5)\n",
    "        \n",
    "        y = test[i,2]\n",
    "        Loss += -( y*np.log(sigf3) + (1-y)*np.log(1-sigf3) )\n",
    "        if y_hat == test[i,2]:\n",
    "            test_correct+=1\n",
    "    print(\"\\tAverage Loss is: \" + str(Loss/10000))\n",
    "    print(\"\\tTest Accuracy: \" + str(test_correct/10000*100) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ohneYiithP69"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 323064,
     "status": "ok",
     "timestamp": 1552700261360,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "LiFEm70nOy8h",
    "outputId": "1f2638eb-713e-4cca-a4cb-fba278284f33"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Accuracy: 82.282%\n",
      "\tAverage Loss is: [[0.65701566]]\n",
      "\tTest Accuracy: 69.92%\n"
     ]
    }
   ],
   "source": [
    "######## (C) Increased Width from 10 to 15 ########\n",
    "\n",
    "def sigmoid(f1):\n",
    "    sig = 1/( 1+np.exp(-f1) )\n",
    "    return sig\n",
    "\n",
    "### Weights and bias Initialization\n",
    "w1 = np.random.uniform(-2,2,(15,2))\n",
    "b1 = np.random.uniform(-1500, 1400, (15,1))\n",
    "\n",
    "w2 = np.full((2,15), 1.0)\n",
    "b2 = np.full((2,1), 0.0)\n",
    "\n",
    "w3 = np.full((1,2), 1.0)\n",
    "b3= 0\n",
    "\n",
    "## Number of iterations and stepsize hyperparameter\n",
    "iter_n = 100\n",
    "step = 0.1\n",
    "decay_counter = 0\n",
    "## Training\n",
    "for p in range(iter_n):\n",
    "    decay_counter += 1\n",
    "    if decay_counter == 20:\n",
    "        step*=0.1\n",
    "        decay_counter = 0\n",
    "    correct = 0\n",
    "    for i in range(50000):\n",
    "        x = np.array([data[i][0],data[i][1]])\n",
    "        x = x.reshape(2,1)\n",
    "\n",
    "        f1 = w1.dot(x) + b1 #1x10\n",
    "        sigf1 = sigmoid(f1) #1x10\n",
    "\n",
    "        f2 = w2.dot(sigf1) + b2 #1x2\n",
    "        sigf2 = sigmoid(f2) #1x2\n",
    "\n",
    "        f3 = w3.dot(sigf2) + b3 # C\n",
    "        sigf3 = sigmoid(f3)\n",
    "        y_hat = 1*(sigf3>0.5)\n",
    "\n",
    "        ## Gradient of w3, b3\n",
    "        dsigf3 = -(data[i,2]/sigf3) + (1-data[i,2])/(1-sigf3) # C\n",
    "        df3 = dsigf3 * ( sigf3 * (1-sigf3) ) # C\n",
    "        dw3 = df3 * sigf2.T #1x2\n",
    "        db3 = df3 # C\n",
    "\n",
    "        ## Gradient of w2, b2\n",
    "        dsigf2 = df3 * w3 #1x2\n",
    "        df2 = dsigf2.T * ( sigf2 * (1-sigf2) ) #1x2\n",
    "        dw2 = df2.dot(sigf1.T) #2x10\n",
    "        db2 = df2 #1x2\n",
    "\n",
    "        ## Gradient of w1, b1\n",
    "        dsigf1 = df2.T.dot(w2) #1x10\n",
    "        df1 = dsigf1.T * ( sigf1 * (1-sigf1) ) #10x1\n",
    "        dw1 = df1.dot(x.T) #10x2\n",
    "        db1 = df1\n",
    "\n",
    "        ## BP\n",
    "        w1 -= step*dw1\n",
    "        b1 -= step*db1\n",
    "\n",
    "        w2 -= step*dw2\n",
    "        b2 -= step*db2\n",
    "\n",
    "        w3 -= step*dw3\n",
    "        b3 -= step*db3\n",
    "\n",
    "        if p == iter_n - 1:\n",
    "            if y_hat == data[i,2]:\n",
    "                correct+=1\n",
    "print(\"\\tTrain Accuracy: \" + str(correct/50000*100) + \"%\")\n",
    "\n",
    "### Testing\n",
    "Loss = 0\n",
    "test_correct = 0\n",
    "for i in range(len(test)):\n",
    "    x = np.array([test[i][0],test[i][1]])\n",
    "    x = x.reshape(2,1)\n",
    "\n",
    "    f1 = w1.dot(x) + b1 #1x10\n",
    "    sigf1 = sigmoid(f1) #1x10\n",
    "\n",
    "    f2 = w2.dot(sigf1) + b2 #1x2\n",
    "    sigf2 = sigmoid(f2) #1x2\n",
    "\n",
    "    f3 = w3.dot(sigf2) + b3 # C\n",
    "    sigf3 = sigmoid(f3)\n",
    "    y_hat = 1*(sigf3>0.5)\n",
    "\n",
    "    if y_hat == test[i,2]:\n",
    "        test_correct+=1\n",
    "    y = test[i,2]\n",
    "    Loss += -( y*np.log(sigf3) + (1-y)*np.log(1-sigf3) )\n",
    "print(\"\\tAverage Loss is: \" + str(Loss/10000))\n",
    "print(\"\\tTest Accuracy: \" + str(test_correct/10000*100) + \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 257,
     "status": "ok",
     "timestamp": 1552701780341,
     "user": {
      "displayName": "Xi Wang",
      "photoUrl": "",
      "userId": "14282931480726339478"
     },
     "user_tz": 240
    },
    "id": "9q8e5j47qSvI",
    "outputId": "82583e7a-be5d-4207-9237-67c40d49bc88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Accuracy: 82.282%\n",
      "\tAverage Loss is: [[0.6581213]]\n",
      "\tTest Accuracy: 69.92%\n"
     ]
    }
   ],
   "source": [
    "######## Increased Depth with an extra layer ########\n",
    "\n",
    "def sigmoid(f1):\n",
    "    sig = 1/( 1+np.exp(-f1) )\n",
    "    return sig\n",
    "\n",
    "### Weights and bias Initialization\n",
    "w1 = np.random.uniform(-2,2,(10,2))\n",
    "b1 = np.random.uniform(-1500, 1400, (10,1))\n",
    "\n",
    "w2 = np.full((5,10), 1.0)\n",
    "b2 = np.full((5,1), 0.0)\n",
    "\n",
    "wplus = np.full((2,5), 1.0)\n",
    "bplus = np.full((2,1), 0.0)\n",
    "\n",
    "w3 = np.full((1,2), 1.0)\n",
    "b3 = 0\n",
    "\n",
    "## Number of iterations and stepsize hyperparameter\n",
    "iter_n = 100\n",
    "step = 100\n",
    "decay_counter = 0\n",
    "## Training\n",
    "for p in range(iter_n):\n",
    "    decay_counter += 1\n",
    "    if decay_counter == 20:\n",
    "        step*=0.1\n",
    "        decay_counter = 0\n",
    "    correct = 0\n",
    "    for i in range(50000):\n",
    "        x = np.array([data[i][0],data[i][1]])\n",
    "        x = x.reshape(2,1)\n",
    "\n",
    "        f1 = w1.dot(x) + b1 #1x10\n",
    "        sigf1 = sigmoid(f1) #1x10\n",
    "\n",
    "        f2 = w2.dot(sigf1) + b2 #1x2\n",
    "        sigf2 = sigmoid(f2) #1x2\n",
    "        \n",
    "        fplus = wplus.dot(sigf2) + bplus #2x1\n",
    "        sigplus = sigmoid(fplus) #2x1\n",
    "\n",
    "        f3 = w3.dot(sigplus) + b3 # C\n",
    "        sigf3 = sigmoid(f3)\n",
    "        y_hat = 1*(sigf3>0.5)\n",
    "\n",
    "        ## Gradient of w3, b3\n",
    "        dsigf3 = -(data[i,2]/sigf3) + (1-data[i,2])/(1-sigf3) # C\n",
    "        df3 = dsigf3 * ( sigf3 * (1-sigf3) ) # C\n",
    "        dw3 = df3 * sigplus.T #1x2\n",
    "        db3 = df3 # C\n",
    "\n",
    "        ## Gradient of wplus, bplus\n",
    "        dsigfplus = df3 * w3 #1x2\n",
    "        dfplus = dsigfplus.T * ( sigplus * (1-sigplus) ) #2x1\n",
    "        dwplus = dfplus.dot(sigf2.T) #2x2\n",
    "        dbplus = dfplus #2x1\n",
    "        \n",
    "        ## Gradient of w2, b2\n",
    "        dsigf2 = dfplus.T.dot(wplus) #1x2\n",
    "        df2 = dsigf2.T * ( sigf2 * (1-sigf2) ) #1x2\n",
    "        dw2 = df2.dot(sigf1.T) #2x10\n",
    "        db2 = df2 #1x2\n",
    "        \n",
    "        ## Gradient of w1, b1\n",
    "        dsigf1 = df2.T.dot(w2) #1x10\n",
    "        df1 = dsigf1.T * ( sigf1 * (1-sigf1) ) #10x1\n",
    "        dw1 = df1.dot(x.T) #10x2\n",
    "        db1 = df1\n",
    "\n",
    "        ## BP\n",
    "        w1 -= step*dw1\n",
    "        b1 -= step*db1\n",
    "\n",
    "        w2 -= step*dw2\n",
    "        b2 -= step*db2\n",
    "        \n",
    "        wplus -= step*dwplus\n",
    "        bplus -= step*dbplus\n",
    "        \n",
    "        w3 -= step*dw3\n",
    "        b3 -= step*db3\n",
    "\n",
    "        if p == iter_n - 1:\n",
    "            if y_hat == data[i,2]:\n",
    "                correct+=1\n",
    "print(\"\\tTrain Accuracy: \" + str(correct/50000*100) + \"%\")\n",
    "\n",
    "### Testing\n",
    "test_correct = 0\n",
    "Loss = 0\n",
    "for i in range(len(test)):\n",
    "    x = np.array([test[i][0],test[i][1]])\n",
    "    x = x.reshape(2,1)\n",
    "\n",
    "    f1 = w1.dot(x) + b1 #1x10\n",
    "    sigf1 = sigmoid(f1) #1x10\n",
    "\n",
    "    f2 = w2.dot(sigf1) + b2 #1x2\n",
    "    sigf2 = sigmoid(f2) #1x2\n",
    "\n",
    "    fplus = wplus.dot(sigf2) + bplus #2x1\n",
    "    sigplus = sigmoid(fplus) #2x1\n",
    "\n",
    "    f3 = w3.dot(sigplus) + b3 # C\n",
    "    sigf3 = sigmoid(f3)\n",
    "    y_hat = 1*(sigf3>0.5)\n",
    "\n",
    "    if y_hat == test[i,2]:\n",
    "        test_correct+=1\n",
    "    y = test[i,2]\n",
    "    Loss += -( y*np.log(sigf3) + (1-y)*np.log(1-sigf3) )\n",
    "print(\"\\tAverage Loss is: \" + str(Loss/10000))\n",
    "print(\"\\tTest Accuracy: \" + str(test_correct/10000*100) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VjJQo8fiWzyw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qzu4jTvUWzyz"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Xi_Wang_HW4_Q1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
