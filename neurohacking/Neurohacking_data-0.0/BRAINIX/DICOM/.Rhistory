theme(axis.text.x = element_text(size = 10, angle = 90,vjust=0))
#plot
ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()+
theme(axis.text.x = element_text(size = 10, angle = 90,vjust=0))
#merge the data
dat1 = read.csv('https://raw.githubusercontent.com/jhu-advdatasci/2018/master/data/KFF/healthcare-spending.csv',skip=2)[1:52,]
dat2 = read.csv('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip =1, sep ='\t')
colnames(dat2) = c('Region','Location')
dat  = left_join(dat1,dat2,by = 'Location')
#Exclude some regions
colnames(dat)[c(-1,-26)] =c(1991:2014)
dat = mutate(dat,avgSpending = apply(dat[c(-1,-26)], 1, mean))
rownames(dat) = dat[,1]
dat = dat[!rownames(dat) %in% c('Connecticut','United States','District of Columbia'),]
#plot
ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()+
theme(axis.text.x = element_text(size = 10, angle = 90,vjust=0))
#merge the data
dat1 = read.csv('https://raw.githubusercontent.com/jhu-advdatasci/2018/master/data/KFF/healthcare-spending.csv',skip=2)[1:52,]
dat2 = read.csv('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip =1, sep ='\t')
colnames(dat2) = c('Region','Location')
dat  = left_join(dat1,dat2,by = 'Location')
#Exclude some regions
colnames(dat)[c(-1,-26)] =c(1991:2014)
dat = mutate(dat,avgSpending = apply(dat[c(-1,-26)], 1, mean))
rownames(dat) = dat[,1]
dat = dat[!rownames(dat) %in% c('Connecticut','United States','District of Columbia'),]
#plot
ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
#plot
plotly(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
#plot
ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
plotly(dat,x = ~Region,y = ~avgSpending, fill =~Location, type = 'bar')
plot_ly(dat,x = ~Region,y = ~avgSpending, fill =~Location, type = 'bar')
plot_ly(dat,x = ~Region,y = ~avgSpending, type = 'bar') %>% add_trace(y = ~Location)
plot_ly(dat,x = ~Region,y = ~avgSpending, type = 'bar')
#plot
ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
plot_ly(dat,x = ~Region,y = ~avgSpending, type = 'bar') %>% add_trace(y = ~Location)
plot_ly(dat,x = ~Region,y = ~avgSpending, type = 'bar') %>%
add_trace(y = ~Location)%>%
layout(barmode = 'stack')
#plot
ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
plot_ly(dat,x = ~Region,y = ~avgSpending, type = 'bar', color = ~Location)
plot_ly(dat,x = ~Region,y = ~avgSpending, type = 'bar', color = ~Location)
plot_ly(dat,x = ~Region,y = ~avgSpending, color = ~Location)
plot_ly(dat,x = ~Region,y = ~avgSpending, barmode = 'stackbar', color = ~Location)
plot_ly(dat,x = ~Region,y = ~avgSpending, barmode = 'stack', color = ~Location)
plot_ly(dat,x = ~Region,y = ~avgSpending,  color = ~Location) %>%
layout(barmode = 'stack')
dat2 = read.csv('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',header=1, sep ='\t')
dat2 = read.csv('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip = 1, sep ='\t')
dat2 = read.csv('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip = 0, sep ='\t')
dat2 = read.table('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip = 0, sep ='\t')
dat2 = read.table('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip = 1, sep ='\t')
colnames(dat2) = c('Region','Location')
dat  = left_join(dat1,dat2,by = 'Location')
#Exclude some regions
colnames(dat)[c(-1,-26)] =c(1991:2014)
dat = mutate(dat,avgSpending = apply(dat[c(-1,-26)], 1, mean))
#merge the data
dat1 = read.csv('https://raw.githubusercontent.com/jhu-advdatasci/2018/master/data/KFF/healthcare-spending.csv',skip=2)[1:52,]
dat2 = read.table('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip = 1, sep ='\t')
colnames(dat2) = c('Region','Location')
dat  = left_join(dat1,dat2,by = 'Location')
#Exclude some regions
colnames(dat)[c(-1,-26)] =c(1991:2014)
dat = mutate(dat,avgSpending = apply(dat[c(-1,-26)], 1, mean))
rownames(dat) = dat[,1]
dat = dat[!rownames(dat) %in% c('United States','District of Columbia'),]
#plot
ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
plot_ly( x = ~Region, y = ~avgSpending, color= ~Location, type = ‘bar’)%>%
plot_ly( x = ~Region, y = ~avgSpending, color= ~Location, type = 'bar')%>%
layout(yaxis = list(title = ‘Average Spending’), barmode = ‘stack’)
plot_ly(dat,x =~Region, y = ~avgSpending, color= ~Location, type = 'bar')%>%
layout(yaxis = list(title = ‘Average Spending’), barmode = ‘stack’)
plot_ly(dat,x =~Region, y = ~avgSpending, color= ~Location, type = 'bar')%>%
layout(yaxis = list(title = 'Average Spending'), barmode = 'stack')
plot_ly(dat,x =~Region, y = ~avgSpending, color= ~Location)%>%
layout(yaxis = list(title = 'Average Spending'), barmode = 'stack')
plot_ly(dat,x =~Region, y = ~avgSpending, color= ~Location, type = 'bar')%>%
layout(yaxis = list(title = 'Average Spending'), barmode = 'stack')
library(MRIcloudT1volumetrics)
library(dplyr)
library(magrittr)
library(ggplot2)
library(plotly)
#merge the data
dat1 = read.csv('https://raw.githubusercontent.com/jhu-advdatasci/2018/master/data/KFF/healthcare-spending.csv',skip=2)[1:52,]
dat2 = read.table('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip = 1, sep ='\t')
colnames(dat2) = c('Region','Location')
dat  = left_join(dat1,dat2,by = 'Location')
#Exclude some regions
colnames(dat)[c(-1,-26)] =c(1991:2014)
dat = mutate(dat,avgSpending = apply(dat[c(-1,-26)], 1, mean))
rownames(dat) = dat[,1]
dat = dat[!rownames(dat) %in% c('United States','District of Columbia'),]
#plot
# ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
plot_ly(dat,x =~Region, y = ~avgSpending, color= ~Location, type = 'bar')%>%
layout(yaxis = list(title = 'Average Spending'), barmode = 'stack')
#merge the data
dat1 = read.csv('https://raw.githubusercontent.com/jhu-advdatasci/2018/master/data/KFF/healthcare-spending.csv',skip=2)[1:52,]
dat2 = read.table('https://raw.githubusercontent.com/bcaffo/ds4bme/master/data/federalRegions.txt',skip = 1, sep ='\t')
colnames(dat2) = c('Region','Location')
dat  = left_join(dat1,dat2,by = 'Location')
#Exclude some regions
colnames(dat)[c(-1,-26)] =c(1991:2014)
dat = mutate(dat,avgSpending = apply(dat[c(-1,-26)], 1, mean))
rownames(dat) = dat[,1]
dat = dat[!rownames(dat) %in% c('United States','District of Columbia'),]
#plot
# ggplot(dat, aes(Region,y = avgSpending,fill = Location)) + geom_col()
plot_ly(dat,x =~Region, y = ~avgSpending, color= ~Location, type = 'bar')%>%
layout(yaxis = list(title = 'Average Spending'), barmode = 'stack')
c(1:10) in c(5:15)
1:10
1:10 in 5:15
c(1:10)
c(1:10) in c(5:15)
table(rbinom(30,5,0.5))
rbinom(30,5,0.5)
?rbinom
rbinom(30,5,0.1)
a = rbinom(30,10,0.5)
barplot(table(a)
a = rbinom(30,10,0.5)
barplot(table(a))
table(rbinom(30,10,5))
table(rbinom(30,10,0.5))
qbinom(0,10,0.5)
qbinom(1,10,0.5)
qbinom(0.95,10,0.5)
qbinom(0.95,100,0.5)
qbinom(0.95,1000,0.5)
qbinom(1,1000,0.5)
qbinom(0.95,1000,0.5)
pbinom(526,1000,0.5)
?range
range(1,10)
range(1:10)
1:10
x = 1:200
y = list()
y
y[0]
y[1]
x
is.array(x)
attributes(x)
attr(x)
?seq
y = []
y = matrix()
y
y = array()
y
y[0]
y[1]
y[2]
y[1]
x = 1:200
y = array()
barplot(x,y)
x = 1:200
y = array()
for (size in x)
{
y[i] = qbinom(0.95,size,0.5)/size
}
x = 1:200
y = array()
for (size in x)
{
y[size] = qbinom(0.95,size,0.5)/size
}
barplot(x,y)
x
y
as.data.frame(y)
x = 1:200
y = array()
for (size in x)
{
y[size] = qbinom(0.95,size,0.5)/size
}
y = as.data.frame(y)
library(ggplot2)
library(ggplot2)
x = 1:200
y = array()
for (size in x)
{
y[size] = qbinom(0.95,size,0.5)/size
}
ggplot(dat = y)
library(ggplot2)
x = 1:200
y = array()
for (size in x)
{
y[size] = qbinom(0.95,size,0.5)/size
}
y = as.data.frame(y)
ggplot(dat = y)+geom_bar()
attributes(y)
y
ggplot(dat = y, aes(y = y))+geom_bar()
library(ggplot2)
x = 1:200
y = array()
for (size in x)
{
y[size] = qbinom(0.95,size,0.5)/size
}
y = as.data.frame(y)
ggplot(y)+geom_bar(aes(x=1:200))
library(ggplot2)
x = 1:200
y = array()
for (size in x)
{
y[size] = qbinom(0.95,size,0.5)/size
}
barplot(x,y)
y = as.data.frame(y)
ggplot(y)+geom_bar(aes(x=1:200))
ggplot(data = as.data.frame(y))+geom_bar()
ggplot(data = as.data.frame(y),aes(x=1:200,y = y))+geom_bar()
y
y$y
library(ggplot2)
X = 1:200
Y = array()
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
barplot(X,Y)
ggplot(data = as.data.frame(Y),aes(x=1:200,y = Y))+geom_bar()
dat = as.data.frame(Y)
colnames(dat) = col
View(dat)
colnames(dat) = 'col'
ggplot(data = dat,aes(x=1:200,y = col))+geom_bar()
Y.rownames
rownames(Y)
ggplot(data = as.data.frame(Y),aes(y = col))+geom_bar()
barplot(X,Y)
barplot(X,Y,xlab = Coverage, ylab=(number of reads)/(coverage))
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
library(ggplot2)
X = 1:200
Y = array()
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
X = 1:200
Y = array()
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
ggplot(data = Y) + geom_col()
library(ggplot2)
Y = as.data.frame(Y)
ggplot(data = Y) + geom_col()
ggplot(data = Y) + geom_col(aes(x = y))
X = 1:200
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
plot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
X = 1:200
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
View(Y)
Y = vector()
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
Y = as.data.frame(Y)
View(Y)
ggplot(data=Y,aes(Y))+geom_bar()
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
X = 1:200
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
X = 1:200
Y = vector()
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
barplot(X,Y,xlab = 'Coverage', ylab='(number of reads)/(coverage)')
1:10
c(1:10)
ggplot(data = as.data.frame(Y),aes(x=1:200,y=Y))+geom_point()
Y
X = 1:200
Y = vector()
for (size in X)
{
Y[size] = qbinom(0.95,size,0.5)/size
}
library(ggplot2)
ggplot(data = as.data.frame(Y),aes(x=1:200,y=Y))+geom_point()
qbinorm
qbinom(0.95,10,0.5)
pbinom(8,10,0.5)
pbinom(7,10,0.5)
qbinom(0.95,100,0.5)
install
install.packages('rsconnect')
USA
USArrests
data.frame(
X1=c(148, 139, 160, 149, 159, 142, 153, 150, 151, 139,
140, 161, 158, 140, 137, 152, 149, 145, 160, 156,
151, 147, 157, 147, 157, 151, 144, 141, 139, 148),
X2=c(41, 34, 49, 36, 45, 31, 43, 43, 42, 31,
29, 47, 49, 33, 31, 35, 47, 35, 47, 44,
42, 38, 39, 30, 48, 36, 36, 30, 32, 38),
X3=c(72, 71, 77, 67, 80, 66, 76, 77, 77, 68,
64, 78, 78, 67, 66, 73, 82, 70, 74, 78,
73, 73, 68, 65, 80, 74, 68, 67, 68, 70),
X4=c(78, 76, 86, 79, 86, 76, 83, 79, 80, 74,
74, 84, 83, 77, 73, 79, 79, 77, 87, 85,
82, 78, 80, 75, 88, 80, 76, 76, 73, 78)
)
dat$cluster == 1
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(raw_dat,iter.max=20,centers = 3)
dat
# sort(dat$cluster)
dat$cluster == 1
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(raw_dat,iter.max=20,centers = 3)
dat
sort(dat$cluster)
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(t(raw_dat),iter.max=20,centers = 3)
dat
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(raw_dat,iter.max=20,centers = 3)
dat
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(t(raw_dat),iter.max=20,centers = 3)
dat
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(raw_dat,iter.max=20,centers = 3)
dat
View(raw_dat)
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(t(raw_dat),iter.max=20,centers = 3)
dat
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(raw_dat,iter.max=20,centers = 3)
dat
View(raw_dat)
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(t(raw_dat),iter.max=20,centers = 3)
dat
View(dat)
?scale
set.seed(100)
raw_dat = read.table('expression.txt',header = 1,row.names = 'name')
raw_dat = as.matrix(raw_dat)
dat = kmeans(t(scale(t(raw_dat))),iter.max=20,centers = 3)
dat
temp = sample_n(raw_dat,10)
library(dplyr)
temp = sample_n(raw_dat,10)
temp = sample_n(raw_dat,10)
library(dplyr)
temp = sample_n(raw_dat,10)
raw_dat = read.table('data1.txt')
temp = sample_n(raw_dat,10)
temp
unlist(temp)
names(unlist(temp))
colnames(temp) = 'first'
temp
unlist(temp)
mode(temp)
is.list(temp)
temp$first
?exp
?pexp
pexp(10,0.5)
?qnorm
qnorm(0.5,0,1)
qnorm(1,0,1)
qnorm(0.99,0,1)
qnorm(0.9999999999,0,1)
dat <- read.csv("task1.csv", header = FALSE)
dat <- read.csv('task1.csv;, header = FALSE)
dat <- read.csv('task1.csv', header = FALSE)
library(readr)
task1_copy_1 <- read_csv("task1_copy-1.csv",head=F)
task1_copy_1 <- read_csv("task1_copy-1.csv",header = F)
?read_csv
task1_copy_1 <- read_csv("task1_copy-1.csv",col_names = 1)
task1_copy_1 <- read_csv("task1_copy-1.csv",col_names = T)
View(task1_copy_1)
task1_copy_1 <- read_csv("task1_copy-1.csv",col_names = F)
View(task1_copy_1)
dat <- read.csv('task1_copy-1.csv', header = FALSE)
View(dat)
View(task1_copy_1)
sum(dat!=task1_copy_1)
sum(dat -= task1_copy_1)
sum(dat == task1_copy_1)
dat == task1_copy_1
NA == NA
dat <- read.csv('task1_copy-1.csv', header = FALSE)
dat2 <- dat[,1 : 10]
View(dat2)
View(dat)
dat2 <- dat2[complete.cases(dat2),]
?complete.cases
vec1 <- as.vector(unlist(dat2))
vec1
unlist(dat2)
?unlist
as.vector(unlist(dat2))
chisq.test(table(vec1))
?chisq.test
rchisq(10)
rchisq(10,df = 1)
rchisq(100,df = 1)
density(rchisq(100,1))
plot(density(rchisq(100,1)))
qplot
library(ggplot2)
qplot(density(rchisq(100,1)))
a = c(1,2,3)
b= c (4,5,6)
data.frame(a,b)
if (!require(devtools)){
install.packages("devtools")
}
install.packages("oro.nifti")
install.packages("oro.dicom")
devtools::install_github("muschellij2/fslr")
devtools::install_github("stnava/ITKR")
devtools::install_github("stnava/ANTsR")
devtools::install_github("muschellij2/extrantsr")
setwd("C:/Users/lcqi/OneDrive/Desktop/Courses/neurohacking/Neurohacking_data-0.0/BRAINIX/DICOM/T1")
slice = readDICOM('IM-0001-0001.dcm')
d = dim(t(slice$img[[1]]))
library(oro.dicom)
slice = readDICOM('IM-0001-0001.dcm')
d = dim(t(slice$img[[1]]))
image(1:d[1],1:d[2],t(slice$img[[1]]),col=gray(0:64/64))
hist(slice$img[[1]],breaks = 50,probability = 1,col=rgb(0,0,1, 0.2))
hdr[hdr$name == 'PixelSpacing','value']
library(oro.nifti)
hist(slice$img[[1]],breaks = 50,probability = 1,col=rgb(0,0,1, 0.2))
hdr[hdr$name == 'PixelSpacing','value']
View(dat)
View(slice)
slice = readDICOM('IM-0001-0001.dcm')
d = dim(t(slice$img[[1]]))
image(1:d[1],1:d[2],t(slice$img[[1]]),col=gray(0:64/64))
image(1:d[1],1:d[2],t(slice$img[[1]]),col=gray(0:64/64))
hdr = slice$hdr
View(slice)
hdr = slice$hdr[[1]]
hist(slice$img[[1]],breaks = 50,probability = 1,col=rgb(0,0,1, 0.2))
hdr[hdr$name == 'PixelSpacing','value']
all_slices_T1 = readDICOM("T1/")
setwd("C:/Users/lcqi/OneDrive/Desktop/Courses/neurohacking/Neurohacking_data-0.0/BRAINIX/DICOM")
all_slices_T1 = readDICOM("T1/")
#all dcm files
nii_T1 = dicom2nifti(all_slices_T1)
#all dcm files
nii_T1 = dicom2nifti(all_slices_T1)
