---
title: "Methods in Biostatistics"
author: "LuchaoQi"
date: "November 23, 2018"
output:
  pdf_document: 
    latex_engine: xelatex
  html_document: default
---



## HW5
### Problem 1
a. MLE for p is 0.818, 0.85 and 0.868 with (2,2), (1,1) and (.5,.5), respectively.   
 The posterior mean is a mixture of the MLE mean estimator and the prior mean
b. CI is [0.6314496 0.9378542], [0.6599475	0.9591231	] and [0.6773164	0.9698094	], respectively. Meaning in interval's lower limit to upper limit was constructed such that in repeated independent experiments, 95% of the intervals obtained would contain p.
```{r}
#1
library(binom)
p=seq(0,1,length=1001)
a=b=2
like=choose(20,17)*p^17*(1-p)^3
prior=gamma(a+b)/(gamma(a)*gamma(b))*p^(a-1)*(1-p)^(b-1)
posterior=prior*like
plot(p,posterior,main="a=b=2")
p[which.max(posterior)]
binom.bayes(17, 20, type = "highest",prior.shape1 = 2,prior.shape2 = 2)
a=b=1
like=choose(20,17)*p^17*(1-p)^3
prior=gamma(a+b)/(gamma(a)*gamma(b))*p^(a-1)*(1-p)^(b-1)
posterior=like*prior
plot(p,posterior,main="a=b=1")
p[which.max(posterior)]
binom.bayes(17, 20, type = "highest",prior.shape1 = 1,prior.shape2 = 1)
a=b=0.5
like=choose(20,17)*p^17*(1-p)^3
prior=gamma(a+b)/(gamma(a)*gamma(b))*p^(a-1)*(1-p)^(b-1)
posterior=like*prior
plot(p,posterior,main="a=b=0.5")
p[which.max(posterior)]
binom.bayes(17, 20, type = "highest",prior.shape1 = 0.5,prior.shape2 = 0.5)
```
Or we could use the code from Lab:
```{r}
library(dplyr) 
library(ggplot2) 
library(latex2exp)
n <- 20 
x <- 17
## Grid of p values 
p <- seq(0.0001, 1 - 0.0001, length = 1000)
## List of prior distribution parameter 
beta.params <- list(c(2, 2), c(1, 1), c(0.5, 0.5))
## lapply: apply over each element of list `beta.params` ## here: param - vector from `beta.params` list ##       p - additional parameter we pass to the function ## ## Calculate priors for different p
priors <- lapply(beta.params, function(param, p)   
  dbeta(p, param[1], param[2]), p = p)
## Calculate posteriors for different p 
posteriors <- lapply(beta.params, function(param, p)   
  dbeta(p, param[1]+ x, n - x + param[2]), p = p)
# Translate into data.frame and plot 
data.frame(p = rep(p, 3),            param = rep(c(2, 1, 0.5), each = 1000),            prior = unlist(priors),             posterior = unlist(posteriors)) %>%   ggplot(aes(x = p, color = factor(param))) +   geom_vline(xintercept = x/n) +    geom_line(aes(y = prior), linetype = 2) +  geom_line(aes(y = posterior)) +    labs(title = "Prior (dashed) and Posterior (solid) Beta Distributions\nblack vertical line: p:=x/n point base d on data only",        x = "p",        y = "PDF",        color = TeX('$\\alpha = \\beta$')) +   theme_bw() +    theme(plot.title = element_text(size = 10)) +   scale_y_continuous(limits = c(0, 10))

```

### Problem 2
Null: true difference in mean equlas to 0  
Alternative hypothesis: true difference in means is not equal to 0  
Assume normality and common variance  
p-value = 0.0007046<0.05  
So we reject null hypothesis
```{r}
x=c(44,265,250,153,88,180,35,494,249,204,
    265,27,68,230,180,149,286,72,39,272)
y=c(44,269,256,154,83,185,36,502,249,208,
    277,39,84,228,187,155,290,80,50,271)
t.test(y-x)

```
### Problem 3
a.
Null: true difference equlas to 0  $H_0=0$
Alternative hypothesis: true difference in means is not equal to 0  $H_A\neq0$
Assume normality and common variance
p-value = 0.01295<0.05  
So we reject null hypothesis
```{r}
x=c(3.22,4.06,3.85,3.5,2.8,3.25,4.2,3.05,2.86,3.5)
y=c(2.95,3.75,4.0,3.42,2.77,3.2,3.9,2.76,2.75,3.32)
dif1=(y-x)
t.test(dif1)
```

b.
```{r}
x=c(3.22,4.06,3.85,3.5,2.8,3.25,4.2,3.05,2.86,3.5)
y=c(2.95,3.75,4.0,3.42,2.77,3.2,3.9,2.76,2.75,3.32)
dif1=(y-x)
power.t.test(delta = mean(dif1), 
             sd = sd(dif1), 
             power = 0.8, 
             sig.level = 0.05, 
             alternative = "two.sided", 
             type = "one.sample")
```
n = 10.30858, so the sample size should be 11.  

### Problem 4
Assume normality 
Null: true difference equlas to 0  
Alternative hypothesis: true difference in means is not equal to 0  
p-value = 0.02188<0.05
We reject null. Also, CI > 0, smokers' pulmonary function declines.
```{r}
x=c(2.85,3.32,3.01,2.95,2.78,2.86,2.78,2.9
    ,2.76,3,3.26,2.84,2.5,3.59,3.3)
y=c(2.88,3.4,3.02,2.84,2.75,3.2,2.96,2.74
    ,3.02,3.08,3,3.4,2.59,3.29,3.32)
dif2=(y-x)
t.test(dif1,dif2,var.equal = TRUE)
```

### Problem 5
```{r}
x=matrix(rnorm(16000,5,1),1000)
y=apply(x,1,mean)
z=apply(x,1,sd)
Y=rep(0,1000)
ts=(y - 5)/(z/sqrt(16))
pval=pt(ts,15)
hist(pval)
```

### Problem 6
a.
Null: $\mu=0$  
Alternative: $\mu\neq0$
```{r}
11+c(-1,1)*qt(0.975,15)*20/sqrt(16)
```
95%CI for relative change is [0.3427523 21.6572477], which does not contain 0. So we conclude that there is statistically significant change in systolic blood pressure.  
b.
```{r}
sp=sqrt((15*20^2+15*28^2)/30)
t=(11-4)/(sp*sqrt(2/16))
2*pt(t,30,lower.tail = FALSE)#p-value
```
p-value =0.4222096>0.05, so we fail to reject null. The change in SBP over the two year period does not differ between oral contraceptive users and controls.  

### Problem 7
Always agrees with same test in kilograms.
Because if we do the test, we could cancel out the constants before mean and standard variance when we do the test.

### Problem 8

An increase in sample size generally will make a study more powerful to detect a difference if one truly exists, but will not shield against false rejection of the null hypothesis (is other words, will not protect from rejecting null hypothesis if there is no difference).
The significance level α is the probability of falsely rejecting null hypothesis, so if a researcher is concerned about falsely rejecting her null hypothesis, she should lower α.

### Problem 9
a.  
```{r}
t <- (0.1) / (0.04 / sqrt(16))
2 * pt(abs(t), df = 16-1, lower.tail = FALSE)
```
p-value = 4.996898e-08 < 0.05  

Therefore we reject the null hypothesis at singificance level $\alpha=0.05$ for this population and conclude that there is a statistically significant change in grey matter.  

b.  If n is small, we have:  
![1.png](C:\Users\lcqi\OneDrive\Desktop\1.png)  
If n is large, we have:  
![2.png](C:\Users\lcqi\OneDrive\Desktop\2.png)  
we choose T test: plug in 
$\mu_0=0$, $\mu_\alpha=0.01$, $n=100$, $\sigma=0.04$  
```{r}
nosim=1000;
n = 100;
sigma = 0.04; 
mu0 = 0; 
mua <- 0.01 
z = rnorm(nosim) 
xsq = rchisq(nosim, df = n-1) 
t = qt(.95, n-1) 
mean(z + sqrt(n) * (mua - mu0) / sigma > t / sqrt(n - 1) * sqrt(xsq))
```

Or we could use following command  
```{r}
power.t.test(n = 100, delta = 0.01/0.04, type = "one.sample", alt = "one.sided") 
```
$power=0.7969757$

### Problem 10

If you reject the null hypothesis for $\alpha=0.05$, this implies the probability of seeing a test statistic as or more extreme than the one you observe is less than 0.05. It follows immediately that this probability is also less than 0.1, leading us to reject the null hypothesis for $\alpha=0.1$ whenever we reject for $\alpha=0.05$

### Problem 11  
```{r}
sp=sqrt((8*1.5^2+8*1.8^2)/16)
4+c(-1,1)*qt(0.975,16)*sp*sqrt(2/9)
TS = 4/(sp*sqrt(2/9))
2*pt(TS,16,lower.tail = FALSE)
```
p-value = 0.0001025174 < 0.05  
95% CI interval = [2.344301 5.655699] which does not contain 0. Meaning the change in BMI over the two year period appear to differ between the treated and placebo groups.