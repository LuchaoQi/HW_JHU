legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
pred_scores3 <- prediction3$posterior[, c("spam")]
pred3 <- prediction(pred_scores3, spamtest[,"type"])
perf3 <- performance(pred3, "tpr", "fpr")
auc3 <- performance(pred3, "auc")
auc3 <- unlist(slot(auc3, "y.values"))
plot(perf3, colorize=TRUE)
title("ROC for Naive Bayes prediction ")
legend('center',legend=parse(text=sprintf('AUC == %s',auc3)))
dev.off()
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
testidx <- which(1:length(spam[,1])%%5 == 0)
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Decision Tree
library(rpart)
model0 <- rpart(type~., data=spamtrain)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Naive Bayes
library(klaR)
model3 <- NaiveBayes(type~., data=spamtrain)
prediction3 <- predict(model3, spamtest[,-58], type= 'raw')
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores0 <- predict(model0, type = "prob")[, 2]
pred0 <- prediction(pred_scores0, spamtest$type)
perf0 <- performance(pred0, "tpr", "fpr")
perf0.auc <- performance(pred0,'auc')
auc0 <- perf0.auc@y.values
plot(perf0,  colorize=TRUE)
title("ROC for Tree Dicision prediction")
legend('center',legend=parse(text=sprintf('AUC == %s',auc0)))
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
pred_scores3 <- prediction3$posterior[, c("spam")]
pred3 <- prediction(pred_scores3, spamtest[,"type"])
perf3 <- performance(pred3, "tpr", "fpr")
auc3 <- performance(pred3, "auc")
auc3 <- unlist(slot(auc3, "y.values"))
plot(perf3, colorize=TRUE)
title("ROC for Naive Bayes prediction ")
legend('center',legend=parse(text=sprintf('AUC == %s',auc3)))
dev.off()
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
testidx <- which(1:length(spam[,1])%%5 == 0)
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Decision Tree
library(rpart)
model0 <- rpart(type~., data=spamtrain)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Naive Bayes
library(klaR)
model3 <- NaiveBayes(type~., data=spamtrain)
prediction3 <- predict(model3, spamtest[,-58], type= 'raw')
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores0 <- predict(model0, type = "prob")[, 2]
pred0 <- prediction(pred_scores0, spamtrain$type)
perf0 <- performance(pred0, "tpr", "fpr")
perf0.auc <- performance(pred0,'auc')
auc0 <- perf0.auc@y.values
plot(perf0,  colorize=TRUE)
title("ROC for Tree Dicision prediction")
legend('center',legend=parse(text=sprintf('AUC == %s',auc0)))
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
pred_scores3 <- prediction3$posterior[, c("spam")]
pred3 <- prediction(pred_scores3, spamtest[,"type"])
perf3 <- performance(pred3, "tpr", "fpr")
auc3 <- performance(pred3, "auc")
auc3 <- unlist(slot(auc3, "y.values"))
plot(perf3, colorize=TRUE)
title("ROC for Naive Bayes prediction ")
legend('center',legend=parse(text=sprintf('AUC == %s',auc3)))
dev.off()
spamtest
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
testidx <- which(1:length(spam[,1])%%5 == 0)
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Decision Tree
library(rpart)
model0 <- rpart(type~., data=spamtrain)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Naive Bayes
library(klaR)
model3 <- NaiveBayes(type~., data=spamtrain)
prediction3 <- predict(model3, spamtest[,-58], type= 'raw')
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores0 <- predict(model0, type = "prob")[, 2]
pred0 <- prediction(pred_scores0, spamtest$type)
perf0 <- performance(pred0, "tpr", "fpr")
perf0.auc <- performance(pred0,'auc')
auc0 <- perf0.auc@y.values
plot(perf0,  colorize=TRUE)
title("ROC for Tree Dicision prediction")
legend('center',legend=parse(text=sprintf('AUC == %s',auc0)))
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
pred_scores3 <- prediction3$posterior[, c("spam")]
pred3 <- prediction(pred_scores3, spamtest[,"type"])
perf3 <- performance(pred3, "tpr", "fpr")
auc3 <- performance(pred3, "auc")
auc3 <- unlist(slot(auc3, "y.values"))
plot(perf3, colorize=TRUE)
title("ROC for Naive Bayes prediction ")
legend('center',legend=parse(text=sprintf('AUC == %s',auc3)))
dev.off()
pred_scores0
length(pred_scores0)
length(spamtest$type)
length(spamtest[,"type"])
length(pred_scores1)
prediction0 <- predict(model0,spamtest, decision.values = TRUE, probability=TRUE)
attr(prediction0, "probabilities")[,1]
attr(prediction0, "probabilities")[,2]
attr(prediction0, "probabilities")
attr(prediction0, "probabilities")
attr(prediction0, "prob")
attr(prediction0, "spam")
attr(prediction0, "type")
prediction1
str(prediction1)
str(prediction0)
length(prediction0[,1])
pred_scores0 <- prediction0[,1]
pred0 <- prediction(pred_scores0, spamtest$type)
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
testidx <- which(1:length(spam[,1])%%5 == 0)
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Decision Tree
library(rpart)
model0 <- rpart(type~., data=spamtrain)
prediction0 <- predict(model0,spamtest, decision.values = TRUE, probability=TRUE)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Naive Bayes
library(klaR)
model3 <- NaiveBayes(type~., data=spamtrain)
prediction3 <- predict(model3, spamtest[,-58], type= 'raw')
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
# pred_scores0 <- predict(model0, type = "prob")[, 2]
pred_scores0 <- prediction0[,1]
pred0 <- prediction(pred_scores0, spamtest$type)
perf0 <- performance(pred0, "tpr", "fpr")
perf0.auc <- performance(pred0,'auc')
auc0 <- perf0.auc@y.values
plot(perf0,  colorize=TRUE)
title("ROC for Tree Dicision prediction")
legend('center',legend=parse(text=sprintf('AUC == %s',auc0)))
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
pred_scores3 <- prediction3$posterior[, c("spam")]
pred3 <- prediction(pred_scores3, spamtest[,"type"])
perf3 <- performance(pred3, "tpr", "fpr")
auc3 <- performance(pred3, "auc")
auc3 <- unlist(slot(auc3, "y.values"))
plot(perf3, colorize=TRUE)
title("ROC for Naive Bayes prediction ")
legend('center',legend=parse(text=sprintf('AUC == %s',auc3)))
dev.off()
str(prediction0)
str(prediction1)
## Load dataset
set.seed(3)
data(spam)
?set.seed
?which
1:length(spam[,1])%%5
q = length(spam)
q
spam
View(spam)
View(spam)
dim(soam)
dim(spam)
spam[1,]
dim(spam)
set.seed(1:10,4,replace = FALS)
set.seed(1:10,4,replace = FALSE)
?set.seed
set.seed(1:10,4,replace = F)
sample(1:10,4,replace = F)
# testidx <- which(1:length(spam[,1])%%5 == 0)
testid <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)
# testidx <- which(1:length(spam[,1])%%5 == 0)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
# testidx <- which(1:length(spam[,1])%%5 == 0)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
dim(spam)
attributes(spam)
str(spam)
length(spam[,1])
# testidx <- which(1:length(spam[,1])%%5 == 0)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)#randomly choose split the dataset
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
# testidx <- which(1:length(spam[,1])%%5 == 0)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)#randomly choose split the dataset
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
dev.off()
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
# testidx <- which(1:length(spam[,1])%%5 == 0)
set.seed(1)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)#randomly choose split the dataset
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
dev.off()
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
# testidx <- which(1:length(spam[,1])%%5 == 0)
set.seed(100)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)#randomly choose split the dataset
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
dev.off()
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
# testidx <- which(1:length(spam[,1])%%5 == 0)
set.seed(100)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)#randomly choose split the dataset
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
dev.off()
#Get	the	spam	database	into	R	(install package kernlab)
library(kernlab)
#Split	into	a	training/test	set	of	80%	to	20%
data(spam) # spam dataset has 4601 email samples, 57 features, 2 types (SPAM and NONSPAM)
# testidx <- which(1:length(spam[,1])%%5 == 0)
set.seed(100)
testidx <- sample(1:dim(spam)[1],0.2*dim(spam)[1],replace = FALSE)#randomly split the data into two parts
spamtrain <- spam[-testidx,] #3680 samples (80% for training set)
spamtest <- spam[testidx,] #920 samples (20% for test set)
#Use SVM	with	2	kernels	of your	choice
library(e1071)
model1 <- svm(type~.,data=spamtrain, kernel = "radial", probability = TRUE) #use radial kernel, untuned
prediction1 <- predict(model1,spamtest, decision.values = TRUE, probability=TRUE)
model2 <- svm(type~.,data=spamtrain, kernel = "linear", probability = TRUE) #use linear kernet, untuned
prediction2 <- predict(model2,spamtest, decision.values = TRUE, probability=TRUE)
#Plot	ROC	curve	for	both	SVM	predictions	(Figure1.pdf)
#Report AUC for each on legend
library(ROCR)
pdf('Figure1.pdf')
pred_scores1 <- attr(prediction1, "probabilities")[,1]
pred1 <- prediction(pred_scores1, spamtest[,"type"])
perf1 <- performance(pred1, "tpr", "fpr") #plots TP rate on y-axis, FP rate on x-axis
perf1.auc <- performance(pred1,'auc')
auc1 <- perf1.auc@y.values
plot(perf1,  colorize=TRUE)
title("ROC for SVM prediction w/ Radial Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc1)))
pred_scores2 <- attr(prediction2, "probabilities")[,1]
pred2 <- prediction(pred_scores2, spamtest[,"type"])
perf2 <- performance(pred2, "tpr", "fpr")
perf2.auc <- performance(pred2,'auc')
auc2 <- perf2.auc@y.values
plot(perf2, colorize=TRUE)
title("ROC for SVM prediction w/ Linear Kernel")
legend('center',legend=parse(text=sprintf('AUC == %s',auc2)))
dev.off()
#Perform 10-fold cross-validation on one of the SVM predictions
library(kernlab)
library(e1071)
library(ROCR)
data(spam)
#Split spam data into 10 equally sized part
folds <- rep(1:10,len=nrow(spam))
testScore <- list()
testLabel <- list()
for (j in 1:10){
testidx <- which(folds == j)
testGroup <- spam[testidx,]
trainGroup <- spam[-testidx,]
model1 <- svm(type~.,data=testGroup, kernel = "radial", probability = TRUE) #use the radial kernel model
predictions <- predict(model1,testGroup, decision.values = TRUE, probability=TRUE)
pred_scores <- attr(predictions, "probabilities")[,1]
testLabel[j] <- list(testGroup[,"type"])
testScore[j] <- list(pred_scores)
}
#Plot ROC curves for each cross-validation fold and corresponding predictions
#With average ROC curve and box plot
pdf('Figure2.pdf')
pred <- prediction(testScore, testLabel)
perf <- performance(pred,"tpr","fpr")
perf.auc <- performance(pred,"auc")
auc <- perf.auc@y.values
plot(perf,col="grey82",lty=3)
plot(perf, lwd=3,avg="vertical",spread.estimate="boxplot",add=T)
title("ROC for 10-fold cross-validation on radial kernal SVM prediction")
legend('center',legend=parse(text=sprintf("AUC==%s",auc)))
dev.off()
